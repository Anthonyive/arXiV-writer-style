\documentclass[11pt]{article}
\usepackage[a4paper, tmargin=3cm, bmargin=3.0cm, lmargin=2.0cm, rmargin=2.0cm, textheight=24cm, textwidth=16cm]{geometry}

\usepackage[breaklinks=true]{hyperref}

\usepackage{setspace}
\usepackage{caption}
\usepackage{amsmath,amsthm,amsfonts,amssymb}
\usepackage{fullpage}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{defn}{Definition}[section]
\newtheorem{rlt}{Theorem}
\renewcommand{\therlt}{\Alph{rlt}}
\newtheorem{lemma}{Lemma}[section]
\newtheorem{prop}{Proposition}[section]
\newtheorem{example}{Example}[section]
\newtheorem{obs}{Observation}
\newtheorem{rem}{Remark}[section]
\newtheorem{cor}{Corollary}[section]
\DeclareMathOperator{\inte }{int}
\DeclareMathOperator{\diag }{diag}
\newtheorem{utheorem}{\textrm{\textbf{Theorem}}}
\renewcommand*{\theutheorem}{\Alph{utheorem}}

\title{Sign non-reversal property for totally positive matrices and testing total positivity on their interval hull}
\author{Projesh Nath Choudhury\thanks{Department of Mathematics, Indian Institute of  Science, Bengaluru. Email: projeshc@iisc.ac.in, projeshnc@alumni.iitm.ac.in}  ~and M. Rajesh Kannan\thanks{Department of Mathematics, Indian Institute of Technology Kharagpur, Kharagpur 721 302, India. Email: rajeshkannan@maths.iitkgp.ac.in, rajeshkannan1.m@gmail.com }
}
\date{\today}
\begin{document}
    \maketitle
    \begin{abstract}We establish a novel characterization of totally positive matrices via a sign non-reversal property. In this we are inspired by the analogous results for $P$-matrices (matrices with all principal minors positive). Next, the interval hull of two $m \times n$ matrices $A=(a_{ij})$ and $B = (b_{ij})$, denoted by $\mathbb{I}(A,B)$, is the collection of all matrices $C$ such that $c_{ij}=t_{ij}a_{ij}+(1-t_{ij})b_{ij}$ for all $i,j$, where $t_{ij} \in [0,1]$.  Using the sign non-reversal property, we identify a finite subset of  $\mathbb{I}(A,B)$ that detects the total positivity of all of $\mathbb{I}(A,B)$. This provides a test for an entire class of matrices simultaneously to be totally positive. We also establish analogous results for other classes of matrices: almost $P$-matrices, $N$-matrices and (minimally) semipositive matrices.

    \end{abstract}

    {\bf AMS Subject Classification(2010):}    15B48, 15A24, 65G30.

    \textbf{Keywords. }  Sign non-reversal, Interval hull of matrices, Totally positive matrices, Almost $P$-matrices, $N$-matrices, Semipositive matrices.
\section{Introduction and main results}
%One of the main objectives of this article is to study the sign non-reversal property for the classes of matrices related to $P$-matrices. As an application of the sign non-reversal property,
%In this article, we establish necessary and sufficient conditions for an interval hull of matrices $\mathbb{I}(A,B)$ to be contained in one of the following classes: totally positive matrices, almost $P$-matrices, $N$-matrices, semipositive and minimally semipositive matrices.

A matrix is totally positive if all its minors are positive. These
matrices have important applications in diverse areas in mathematics,
including approximation theory, combinatorics, cluster algebras,
integrable systems, probability, representation theory, and matrix theory
\cite{BGKI,BGKII,BFZ96,Bre95,FZ02,K68,Lu94,Sch07}. There is a well known
paper by Fomin and Zelevinsky \cite{FZ00} about tests for totally
positive matrices. This paper may be regarded as being similar in spirit.
Namely, $(a)$ we provide a novel characterization of total positivity via
the sign non-reversal property:
 
 \begin{utheorem}\label{tp-sign-rev}
 	A real $m \times n $ matrix $A$ is totally positive if and only if the following holds:
 	
 	If $y=\begin{pmatrix} 0_k\\x\\0_s \end{pmatrix}$, where  $x \in \mathbb{R}^r$ has nonzero components, $k + r + s = n$, $k \geq 0, s \geq  0$ and $0<r \leq \min\{m, n\}$, then for each $j \in \langle m-r+1 \rangle$, there exists $i \in \langle r \rangle$ such that \begin{center} $y_{k+i}(Ay)_{i+j-1} > 0$.\end{center}
 	
 \end{utheorem}
This may bring to mind the parallel and widely studied variation diminishing property, which characterize total positivity.

$(b)$ We provide a test for not just one matrix but an entire interval
hull of matrices to be totally positive, by reducing it to a finite set
of test matrices. Given matrices $A, B \in \mathbb{R}^{m \times n}$,
recall that their interval hull, denoted by  $\mathbb{I}(A,B)$, is
defined as follows:
\begin{equation}
	\mathbb{I}(A,B) = \{C \in \mathbb{R}^{m \times n}: c_{ij} = t_{ij} a_{ij} + (1 - t_{ij}) b_{ij}, t_{ij} \in [0,1]\} \label{hulleqn}.
\end{equation}

If the matrices $A$ and $B$ are different, then the interval hull
contains uncountably many matrices. One of the interesting questions,
related to interval hulls of matrices, considered in the literature is
the following:  Suppose a finite subset of matrices in $\mathbb{I}(A, B)$
has some property, say $\mathcal{S}$. Does the entire interval hull
$\mathbb{I}(A, B)$ have the property $\mathcal{S}$?  For example, if the
matrices $A$ and $B$ are invertible and $A \leq B$ (entry wise), then all
the matrices in the interval hull $\mathbb{I}(A, B)$ are invertible if
and only if ($A,B$ are invertible and) $A^{-1} \geq 0$ (entry wise) and
$B^{-1} \geq 0$ \cite{rohn-inv-pos}. An interval hull $\mathbb{I}(A, B)$ is said to be
\textit{of type} $\mathcal{S}$ if all the matrices in $\mathbb{I}(A,
B)$ are of type $\mathcal{S}$. With this background, our second main
result can now be stated.
\begin{utheorem}\label{tp_hull}
	Let $A, B \in \mathbb{R}^{m \times n}$. Then the interval hull $\mathbb{I}(A, B)$ is  totally positive if and only if the matrix $I_{z z^{'}}$ is totally positive for all $z\in \{ \pm 1 \}^m$ and $z^{\prime}\in \{ \pm 1 \}^n$.
\end{utheorem}
The notation $I_{z z^{'}}$ will be explained at the end of this section.
\begin{rem}
	Both of these results have analogues for totally positive matrices of order $k$ (see Theorem \ref{tp-sign-rev k} and \ref{tp_hull k}).
\end{rem}
In this paper we also work out analogues of  these results for several other classes of matrices:
\begin{defn}\label{maindefn}
	
	\begin{enumerate}
		\item A matrix $A \in \mathbb{R}^{n \times n}$ is   \emph{an $N$-matrix} if all its principal minors are negative.
		\item An $n \times n$ matrix $A$ is \emph{an almost $P$-matrix} if all its principal minors of order up to $(n-1)$ are positive, and the determinant of $A$ is negative.
		\item  An $m \times n$ real matrix $A$ is a  \emph{semipositive matrix},  if there exists a vector $x \geq 0$ such that $Ax > 0$. An $m \times n$ real matrix $A$ is a  \emph{minimally semipositive matrix}, if it is semipositive and no column-deleted submatrix of $A$ is semipositive.
	\end{enumerate}
		
\end{defn}

$N$-matrices have connections to univalence theory (injectivity of
differential maps in $\mathbb{R}^n$) and the Linear Complementarity
Problem \cite{par-rav-nmat}. Recently in \cite{PT20}, the first author joint work with Tsatsomeros has established an algorithm to detect whether a given matrix is an $N$-matrix or not; as well as an algorithm to construct every $N$-matrix recursively. The sign non-reversal property for $N$-matrices was established in \cite{moh-sri-nmat-lcp, par-rav-nmat}. In this paper, we recap these results, and also prove their analogues for the remaining classes of matrices defined above. We further obtain the interval hull characterization for all of these classes. Our results are summarized as follows:
\begin{center}
	
	\begin{tabular}{|c|c|l|l|c|}
		\hline
		
		{\bf Matrix Class} & {\bf Sign non-reversal} & { ~~~\bf $\mathbb{I}(A,B)$} & {\bf Testing set}~\\
		& ~~~~~~~\bf property&& {\bf for} $\mathbb{I}(A,B)$\\
		
		%\bf No. & \bf No. & & \bf Year & \bf Elective~ && \\
		
		\hline Totally positive & ~~Theorem \ref{tp-sign-rev} & Theorem \ref{tp_hull}&~$I_{z z^\prime}, \ z \in \{ \pm 1 \}^m$,\\
		& & & \hspace*{8mm} $z^{\prime} \in \{ \pm 1 \}^n$\\
		
		\hline Totally positive & ~~Theorem \ref{tp-sign-rev k} & Theorem \ref{tp_hull k}&~$I_{z z^\prime}, \ z \in \{ \pm 1 \}^m$,\\
		of order $k$ & && \hspace*{6mm} $z^{\prime} \in \{ \pm 1 \}^n$ \\
		
		\hline Almost $P$-matrices of the & &&\\
		first category with & ~~Theorem \ref{alm-p-1st} & Theorem \ref{almost p 1st hull} &~$I_{z}, \ z \in \{ \pm 1 \}^n$, $I_{P_J}$\\
		with respect to $J$ & && \\
		
		\hline Almost $P$-matrices & ~~Theorem \ref{alm-p-sec} & Theorem \ref{almst p sec hull}&~$I_{z}, \ z \in \{ \pm 1 \}^n$, $I_u$\\
		
		of the second category & && \\
		
		\hline $N$-matrices of the first&  ~\cite[Theorem 4.3]{moh-sri-nmat-lcp} & Theorem \ref{n hull 1st}&~$I_{z}, \ z \in \{ \pm 1 \}^n$\\
		
		category with respect to $J$ & && \\
		
		\hline $N$-matrices of the&  ~~\cite[Theorem 2]{par-rav-nmat} & Theorem \ref{n hull 2nd}&~$I_{z}, \ z \in \{ \pm 1 \}^n$\\
		
		second category & && \\
		
		\hline Semipositive & ~~~~~~~N/A  & Theorem \ref{int-semi}&~$I_{l}$\\
		
		\hline Minimally semipositive  & ~~~~~~~N/A & Theorem \ref{int-semi}&~$I_{l}, I_{u}$\\
		
		\hline
		
	\end{tabular}
	\captionof{table}{Summary of results. Here, $J$ denotes a subset of $\langle n \rangle = \{1,\dots, n\}$.}\label{table1}
\end{center}

We conclude by explaining the notation used above.

\begin{defn}
Fix integers $m,n \geq 1$ and matrices $A, B \in \mathbb{R}^{m \times n}$, with interval hull $\mathbb{I}(A,B)$.
\begin{enumerate}
	\item Define the matrices
	\[
	(I_u)_{ij}:= \max\{a_{ij},b_{ij}\}, \qquad
	(I_l)_{ij}:= \min\{a_{ij},b_{ij}\}, \qquad
	I_c := \frac{B + A}{2}, \qquad
	\Delta := \frac{I_u - I_l}{2}.
	\]
	\item Given $z=(z_1,\dots,z_m) \in \{ \pm 1 \}^m$ and $z^{\prime} \in \{ \pm 1 \}^n$, define the matrices
	\[
	D_z :=\diag(z_1,\dots,z_m), \qquad
	I_{zz^{\prime}} := I_c - D_z\Delta D_{z^{\prime}}.
	\]
	\item If $m=n$, define $I_z := I_c - D_z \Delta D_z$.
\end{enumerate}
\end{defn}


\subsection*{Organization of the paper.}

In Section \ref{secTP}, we collect some known results and prove Theorem \ref{tp-sign-rev} and Theorem \ref{tp_hull}. Section \ref{secnmat} contains the results for $N$-matrices and in Section \ref{sec-alm-p-mat}, we prove the results for almost $P$-matrices and semipositive matrices.
\section{Results for totally positive matrices}\label{secTP}

In this section, we prove the main theorems above on totally positive
matrices. We first develop some preliminary results, and recall past
theorems that will be used below.

\subsection{Preliminaries}

We begin with notation, which will be used throughout the paper without
further reference.
 For a matrix $A \in \mathbb{R}^{m \times n}$, $A \geq 0 ~(A>0)$ signifies that all the components of the matrix $A$ are nonnegative (positive), and let $\vert A\vert := (\vert a_{ij}\vert)$. %$x > 0 $ means that all the components of the vector $x$ are positive. 
  Let $0_k$ denote the column vector of size $k$ whose entries are all
  zero. The diagonal matrix with diagonal entries $x_1, \dots, x_n$ is
  denoted by $\diag(x_1, \dots, x_n)$. For any positive integer $n$,
  define $\langle n \rangle := \{1,\dots, n\}$. Let $\mathbb{R}_\pm^n :=
  \{(x_1\dots,x_n) \in \mathbb{R}^{n}: \pm x_i \geq 0 ~\mbox{for all }~ i
  \in \langle n \rangle \}$.  For a subset $X$ of $\mathbb{R}^n$, let
  $\inte(X)$ denote the interior of $X$ in $\mathbb{R}^n$ with respect to
  the Euclidean metric. Let $e_i$ denote the vector whose $i$-th
  component is $1$, and other entries are zero.

A square matrix $A$ is a \textit{$P$-matrix} if all its principal minors are positive. In \cite{gale-nikai-pmat}, the authors established the sign non-reversal  property for $P$-matrices. \begin{theorem}[Sign non-reversal property]\label{snrp}
	A matrix $A \in \mathbb{R}^{n \times n}$ is a $P$-matrix if and only if $x \in \mathbb{R}^n$ and $x_i(Ax)_i \leq 0$ for all $i$ imply $x=0.$
\end{theorem}
Using the sign non-reversal property of $P$-matrices, in \cite{RJRG}, the
authors showed that the interval hull  of matrices $\mathbb{I}(A, B)$, where $A \leq B$, is a $P$-matrix, if a finite collection of matrices in  $\mathbb{I}(A, B)$ are $P$-matrices. In \cite{rohn1}, the author considered the positive definiteness and  the stability of the interval hulls of matrices.

The next result we require is a well-known theorem of Fekete. Recall that
a contiguous submatrix is one whose rows and columns are indexed by sets of consecutive  positive integers.
		\begin{theorem}[Fekete's criterion, \cite{FP12}]\label{fec}
			Let $A \in \mathbb{R}^{m \times n}$. Then $A$ is
			totally positive if and only if all contiguous
			submatrices of $A$ have positive determinant.
		\end{theorem}

\noindent For more details about totally positive matrices, we refer to \cite{fallat-john,K68,pinkus}.


In order to prove our main results above (as well as later results), we also
require two basic lemmas. The first is a straightforward verification:

\begin{lemma}\label{int-lem1}
    If $A,B \in \mathbb{R}^{m \times n}$, then $I_l, I_u,
    I_{zz^\prime} \in \mathbb{I}(A,B)$ for all $z\in \{ \pm 1 \}^m$ and
    $z^{\prime}\in \{ \pm 1 \}^n$.
\end{lemma}



The next lemma extends \cite[Theorem 2.1]{RJRG} to interval hulls of
arbitrary matrices $A,B$.
\begin{lemma}\label{rohn_exten2}

    Let $A,B \in \mathbb{R}^{n \times n}$ and $x \in \mathbb{R}^n$. Let
    $z \in \{ \pm 1 \}^n$ such that $z_i = 1$ if $x_i \geq 0$ and $z_i = -1$ if $x_i < 0$. If $C \in \mathbb{I}(A,B)$, then
    \begin{center}
        $x_i(Cx)_i\geq x_i (I_z x)_i \hbox{~~ for ~} i\in \langle n \rangle.$
    \end{center}

\end{lemma}

\begin{proof}
    Let  $C \in \mathbb{I}(A,B)$. Then $I_l\leq C \leq I _u$. Since $I_l= I_c- \Delta$ and $I_u= I_c + \Delta$, so \begin{center} $I_c -\Delta \leq C \leq I_{c} + \Delta $ for all $C \in \mathbb{I}(A,B)$.\end{center} 
     Let $ x \in \mathbb{R}^n \setminus \{0\}$.  For fixed $1\leq i \leq n$, we have
    \begin{eqnarray}
    \vert   x_i((C-I_c)x)_i \vert & \leq &\vert x_i \vert (\vert C-I_c\vert \vert x \vert )_i
    \leq \vert x_i \vert ( \Delta  \vert x \vert )_i. \nonumber
    \end{eqnarray}
    Hence $$x_i (Cx)_i  \geq x_i (I_c x)_i - \vert x_i \vert ( \Delta  \vert x \vert )_i .$$
    Since $\vert x_j \vert=z_j x_j $ for each $j$, so $x_i (C x)_i \geq x_i((I_c - D_z \Delta D_z) x)_i$.
\end{proof}


\subsection{Proofs of main results}\label{sec-tp}

With the above results in hand, we now show our main theorems.

\begin{proof}[Proof of Theorem \ref{tp-sign-rev}]
    Let $A$ be a totally positive matrix, and let $y=\begin{pmatrix} 0_k\\x\\0_s \end{pmatrix}$, where  $x \in \mathbb{R}^r$ with $x_i\neq 0$ for all $i$, $k + r + s = n$ , $k \geq 0, s \geq  0$ and $0<r \leq \min\{m, n\}$.
    Fix $j \in \langle m-r+1 \rangle$, and let 
    $B$ be the submatrix of $A$ with rows and columns indexed by the sets $\{j, j+1, \dots, j + r -1\}$ and $\{k+1,\dots,k+r\}$, respectively.
    Then $Ay = \begin{pmatrix} \star\\Bx\\ \star \end{pmatrix}.$
    Since $B$ is a $P$-matrix, there exists $i \in \langle r \rangle$ such that $x_i(Bx)_i > 0$. Thus $y_{k+i}(Ay)_{i+j-1} > 0.$

    We prove the converse using induction. Let $y=e_l$, then $Ae_l = \begin{pmatrix} a_{1l}\\\vdots\\a_{ll}\\\vdots\\a_{ml}\end{pmatrix}$. By assumption, $y_l(Ay)_j > 0$
    for each $j \in \langle m \rangle$.
    Thus $Ae_l>0$, so $A > 0.$ Thus all the $1 \times 1$ minors are positive.
    Let $B$ be any $2 \times 2$ minor of $A$ corresponding to the rows $l$ and $l+1$ and the columns $t$ and $t+1$ of $A$.
    Let $x \in \mathbb{R}^2$ with $x_1, x_2 \neq 0$. Let $y = \begin{pmatrix}0_{t-1}\\x\\0_{n-t-1} \end{pmatrix}$, where $x$ lies in the positions $t$ and $t+1$.
    Then for each $j \in \langle m-1\rangle$, there exists $i \in \{1,2\}$ such that $y_{(t-1)+i}(Ay)_{i+j-1} > 0$. Choose $j=l$, then $(Ay)_j=(Bx)_1$ and $(Ay)_{j+1}=(Bx)_2$. Thus, either $x_1(Bx)_1 > 0$ or $x_2(Bx)_2> 0$.
    So $B$ is a $P$-matrix. Thus all the $2 \times 2$ contiguous minors of $A$ are positive.

    For the induction step, assume that all contiguous minors of $A$ of size less than $d$ are positive. Let $B$ be a $d\times d$ submatrix of $A$ corresponding to the rows $l, l+1,\dots,l+d-1$ and the columns $t, t+1,\dots,t+d-1$. Let $x \in \mathbb{R}^d$ with $x_i \neq 0$, for $i \in \langle d \rangle$ and let $y = \begin{pmatrix}0_{t-1}\\x\\0_{n-t-d-1} \end{pmatrix}$, where $x$ lies in the $t,t+1,\ldots t+d-1$ positions. Then, for $j \in \langle m-d+1 \rangle$, there exists $i \in \langle d \rangle$ such that $y_{(t+i-1)}(Ay)_{i+j-1} > 0$. Set $j = l$. As $Ay = \begin{pmatrix}\star\\ Bx\\ \star \end{pmatrix}$,
    so $(Ay)_{i+j-1}=(Bx)_i$ for $i\in \langle d \rangle$. Thus
    $x_{i}(Bx)_{i} > 0$ for some $i\in \langle d \rangle$, and hence
    $B $ is a $P$-matrix. Therefore all contiguous submatrices of $A$ have
    positive determinants, and so $A$ is totally positive by Theorem
    \ref{fec}.
\end{proof}

Theorem~\ref{tp-sign-rev} helps prove our next main result:

\begin{proof}[Proof of Theorem \ref{tp_hull}]
    Let $I_{z z^{'}}$ be totally positive for all $z\in \{ \pm 1 \}^m$ and $z^{\prime}\in \{ \pm 1 \}^n$, and let $C \in \mathbb{I}(A,B)$. Let $y = \begin{pmatrix}
    0_k\\x\\0_s
    \end{pmatrix} \in \mathbb{R}^n
    $, where $x \in \mathbb{R}^r$, $r\leq \min \{m,n\}$ and the entries of $x$ are nonzero. We claim that, for each $j \in \langle m-r+1 \rangle$, there exists $i \in \langle r \rangle$ such that $y_{k+i} (Cy)_{i+j-1} > 0.$
    Indeed, let $C^{\prime}$ be the  submatrix of $C$ with the rows and the columns indexed by $\{j, j+1, \dots, j+r-1\}$ and $\{k+1, \dots, k+r\}$, respectively. The matrices $A^{'}$ and $B^{'}$ are defined  similarly. Then, $Cy = \begin{pmatrix}
    \star\\ C^{\prime}x \\ \star \end{pmatrix}$. Since $C^{\prime}\in \mathbb{I}(A^{\prime},B^{\prime})$, by Lemma \ref{rohn_exten2}, there exists $z_1 \in \{ \pm 1 \}^r$ such that $x_i(C^{\prime}x)_i \geq x_i((I_c^{'} - D_{z_1}\Delta^{\prime}D_{z_1})x)_i$. Define $z \in \{ \pm 1 \}^m$ and $z^{\prime} \in \{ \pm 1 \}^n$  as follows:  \[
    z_i=\left\{
    \begin{array}{cc}
    (z_1)_i, &\hspace{5mm} \mbox{if } i \in \{j, j+1, \dots, j+r-1\},\\
    1, &\hspace{5mm} \mbox{otherwise},
    \end{array}
    \right.
    \] and
    \[
    z^{\prime}_i=\left\{
    \begin{array}{cc}
    (z_1)_i, &\hspace{5mm} \mbox{if } i \in \{k+1, \dots, k+r\},\\
    1, &\hspace{5mm} \mbox{otherwise}.
    \end{array}
    \right.
    \]

    Then $(I_c^{\prime} - D_{z_1}\Delta^{\prime}D_{z_1})$ is a submatrix of $(I_c - D_{z}\Delta D_{z^{\prime}})$, and hence
    $(I_c^{\prime} - D_{z_1}\Delta^{\prime}D_{z_1})$ is a $P$-matrix, so $x_i(C^{\prime}x)_i > 0$ for some $i\in \langle r \rangle$. That is, $y_{k+i} (Cy)_{i+j-1} > 0$, for some $i\in \langle r \rangle$. By Theorem \ref{tp-sign-rev}, $\mathbb{I}(A, B)$ is  totally positive.
\end{proof}


Both of our main results have analogues for totally positive matrices of
order $k$, for all $k \geq 1$. Recall that a matrix $A \in \mathbb{R}^{m
\times n}$ is called a \textit{totally positive matrix of order $k$} if
all its minors of order at most $k$ are positive.
The next two theorems give the sign non-reversal property and the
characterization of the interval hull $\mathbb{I}(A, B)$ for such matrices $A,B$. The proofs are
similar to those of Theorems \ref{tp-sign-rev} and \ref{tp_hull}
respectively, and we leave the details to the interested reader.

	\begin{theorem}\label{tp-sign-rev k}
		An $m \times n $ matrix $A$ is totally positive of order $k$ if and only if the following holds:
		
		If $y=\begin{pmatrix} 0_l\\x\\0_s \end{pmatrix}$, where  $x \in \mathbb{R}^r$ has nonzero components, $l + r + s = n$, $l \geq 0, s \geq  0$ and $0<r \leq k$, then for each $j \in \langle m-r+1 \rangle$, there exists $i \in \langle r \rangle$ such that \begin{center} $y_{l+i}(Ay)_{i+j-1} > 0$.\end{center}
		
	\end{theorem}

\begin{theorem}\label{tp_hull k}
	Let $A, B \in \mathbb{R}^{m \times n}$. Then the interval hull $\mathbb{I}(A, B)$ is  totally positive of order $k$ if and only if $I_{z z^{\prime}}$ is totally positive of order $k$ for all $z\in \{ \pm 1 \}^m$ and $z^{\prime}\in \{ \pm 1 \}^n$.
\end{theorem}


\section{Results for $N$-matrices}\label{secnmat}


 We now develop similar results to above, for $N$-matrices
(see Definition~\ref{maindefn}). First recall that an $N$-matrix $A$ is
said to be of the \textit{first category} if it has at least one positive
entry. Otherwise, $A$ is of the \textit{second category}.

The following result gives a characterization for $N$-matrices of the
second category. This is known as the sign non-reversal property for the
$N$-matrices of the second category.

\begin{theorem}{\cite[Theorem 2]{par-rav-nmat}}\label{PR}
    Let $A \in \mathbb{R}^{n \times n}$. Then $A$ is an N-matrix of the second category if and only if $A<0$ and $A$ does not reverse the sign of any non-unisigned vector, that is, $x \in \mathbb{R}^n$ and  $x_i(Ax)_i\leq 0 $ for all $i$ imply $x \leq 0$ or $x \geq 0$.
\end{theorem}


 For $J \subseteq \langle n \rangle$, $J^\complement$ denotes $\langle n
 \rangle \setminus J$. For subsets $I, J \subset \langle n \rangle$ with
 elements arranged in ascending order, $A_{IJ}$ denotes the submatrix of
 $A$ whose rows and columns are indexed by $I$ and $J$, respectively.

\begin{theorem}{\cite[Theorem 4.3]{moh-sri-nmat-lcp}} \label{nmat-fir-char1}
    Let $A\in \mathbb{R}^{n \times n}$ be an $N$-matrix of the first category. Then $A$ can be written in the partitioned form (after a principal rearrangement of its rows and columns, if necessary)
    \begin{equation}\label{eq1}
    \begin{pmatrix}
        A_{JJ} & A_{J J^\complement}\\
        A_{J^\complement J} & A_{J^\complement J^\complement}
	\end{pmatrix},
    \end{equation} with $A_{JJ} < 0$, $A_{J^\complement J^\complement}<0$, $A_{JJ^\complement } >0$, and $A_{J^\complement J}>0$, where $J$  is a nonempty proper subset of $ \langle n \rangle$.

\end{theorem}
\begin{defn}\label{defnn1stj}
Let $J$  be a nonempty proper subset of $ \langle n \rangle$.
An $N$-matrix $A$ is called \emph{an $N$-matrix of the first category
with respect to $J$} if  it is of the form  $\begin{pmatrix}
	A_{JJ} & A_{J J^\complement}\\
	A_{J^\complement J} & A_{J^\complement J^\complement} \\
	\end{pmatrix}$ with $A_{JJ} < 0$, $A_{J^\complement J^\complement}<0$, $A_{JJ^\complement } >0$, and $A_{J^\complement J}>0$.
\end{defn}
The next result gives a characterization for $N$-matrices of the first category with respect to $J$, and is known as the sign non-reversal property for such matrices.

\begin{theorem}{\cite[Theorem 4.3]{moh-sri-nmat-lcp}} \label{nmat-fir-char}
    Let $J$ be a nonempty proper subset of $\langle n \rangle$ and let $A = \begin{pmatrix}
        A_{JJ} & A_{J J^\complement}\\
        A_{J^\complement J} & A_{J^\complement J^\complement} \\
        \end{pmatrix}\in \mathbb{R}^{n \times n},$ where $A_{JJ} < 0$, $A_{J^\complement J^\complement}<0$, $A_{J J^\complement } >0$, and $A_{J^\complement J}>0.$ Then $A$  is an $N$-matrix of the first category with respect to $J$ if and only if  $A$ reverses the sign of a vector $x \in \mathbb{R}^n$, i.e, $x_i(Ax)_i\leq 0$ for all $i \in \langle n \rangle$, then either $x_J \leq 0$ and $x_{J^\complement} \geq 0$, or $x_J \geq 0$ and $x_{J^\complement} \leq 0.$

\end{theorem}

We now characterize interval hulls of $N$-matrices, beginning with those
of the second category.
\begin{theorem}\label{n hull 2nd}
	Let $A,B \in \mathbb{R}^{n \times n}$ such that $A<0$ and $B<0$.
	Then, $\mathbb{I}(A,B)$ is an $N$-matrix of the second category  if and only if $I_z$ is an $N$-matrix of the second category for all $z\in \{ \pm 1 \}^n$.
\end{theorem}

\begin{proof}
	Suppose $\mathbb{I}(A,B)$ is an $N$-matrix of the second category,
	then $I_z$ is an $N$-matrix of the second category. Conversely,
	suppose that $I_z$ is an $N$-matrix of the second category for all $z\in \{ \pm 1 \}^n$. Let $x \in \mathbb{R}^n$ and $C \in \mathbb{I}(A,B)$ such that $x_i(Cx)_i\leq 0$ for $i\in \langle n \rangle$. By Lemma \ref{rohn_exten2}, there exists  $z\in \{ \pm 1 \}^n$ such that $0\geq x_i (C x)_i \geq x_i(I_z x)_i$, for $i\in \langle n \rangle$. By Theorem \ref{PR}, $x\leq 0$ or $x\geq 0$, since $I_z$ is $N$-matrix of the second category. Since $A,B<0$, so $C<0$. By Theorem \ref{PR}, $C$ is an $N$-matrix of the second category.
\end{proof}

We next characterize the interval hull of $N$-matrices of the first category with respect to $J$, where $J\subseteq \langle n \rangle$.
\begin{theorem}\label{n hull 1st}
	Let $J$ be a nonempty proper subset of $\langle n \rangle$, and let\begin{center} $A = \begin{pmatrix}
			A_{JJ} & A_{J J^\complement}\\
			A_{J^\complement J} & A_{J^\complement J^\complement} \\
			\end{pmatrix} \mbox{~and~} B = \begin{pmatrix}
			B_{JJ} & B_{J J^\complement}\\
			B_{J^\complement J} & B_{J^\complement  J^\complement} \\
			\end{pmatrix}$\end{center} be two $n \times n$ matrices such that $A_{JJ}, B_{JJ}, A_{J^\complement J^\complement}, B_{J^\complement J^\complement} < 0$, and  $A_{J J^\complement }, B_{J J^\complement}, A_{J^\complement J }, B_{J^\complement J }>0$. Then, $\mathbb{I}(A,B)$ is an $N$-matrix of the first category with respect to $J$  if and only if $I_z$ is an $N$-matrix of the first category with respect to $J$ for all $z\in \{ \pm 1 \}^n$.
\end{theorem}
\begin{proof}
	Suppose $I_z$ is an $N$-matrix of the first category with respect to $J$ for all $z\in \{ \pm 1 \}^n$. Since $I_z \in \mathbb{I}(A,B)$, the block structure of $I_z$ with respect to sign pattern, is independent of $z$ and agrees with that of $A$ and $B$. Let $C \in \mathbb{I}(A,B)$. Then $C$ can be partitioned as $C = \begin{pmatrix}
		C_{JJ} & C_{J J^\complement}\\
		C_{J^\complement J} & C_{J^\complement J^\complement} \\
		\end{pmatrix},$ where $C_{JJ}, C_{J^\complement J^\complement}< 0$, and  $C_{J J^\complement }, C_{J^\complement J }>0$. Let $x \in \mathbb{R}^n$ such that $x_i(Cx)_i\leq 0$ for all $i\in \langle n \rangle$. By Lemma \ref{rohn_exten2}, there exists  $z\in \{ \pm 1 \}^n$ such that $0\geq x_i (C x)_i \geq x_i(I_z x)_i$, for all $i\in \langle n \rangle$. Since $I_z$ is an $N$-matrix of the first category with respect to $J$,  by Theorem \ref{nmat-fir-char},  either $x_J \leq 0$ and $x_{J^\complement} \geq 0$, or $x_J \geq 0$ and $x_{J^\complement} \leq 0.$ Thus, by Theorem \ref{nmat-fir-char}, $C$ is an $N$-matrix of the first category with respect to $J$. Conversely, suppose that $\mathbb{I}(A,B)$ is an $N$-matrix of the first category with respect to $J$. By Lemma \ref{int-lem1}, $I_z \in \mathbb{I}(A,B)$ for all $z\in \{ \pm 1 \}^n$. Thus $I_z$ is an $N$-matrix of the first category with respect to $J$ for all $z\in \{ \pm 1 \}^n$.
\end{proof}

\section{Results for almost $P$-matrices and semipositive matrices}\label{sec-alm-p-mat}

We now establish the sign non-reversal property for almost $P$-matrices
(see Definition \ref{maindefn}) and characterize their interval hull.
Recall that an $n \times n ~(n\geq 2)$ matrix $A$ is an almost $P$-matrix
if and only if $A^{-1}$ is an $N$-matrix \cite[Lemma 2.4]{koji-sai-1979}.
Motivated by this result, we classify almost $P$-matrices into two categories:
\begin{defn}\label{defnalmost p}
	\begin{itemize}
		\item[(i)] Let $J$  be a nonempty proper subset of $ \langle n \rangle$. An almost $P$-matrix $A$ is \emph{an almost $P$-matrix of the first category with respect to $J$} if $A^{-1}$ is an $N$-matrix of the first category with respect to $J$.
		\item[(ii)] An almost $P$-matrix $A$ is an \emph{almost $P$-matrix of the second category} if $A^{-1}$ is an $N$-matrix of the second category.
	\end{itemize}
\end{defn}
Observe that if $A$ is an almost $P$-matrix of the second category, then there exists a
positive vector $x$ such that $Ax<0$. Our next result shows a sign
non-reversal property for such matrices.

\begin{theorem}\label{alm-p-sec}
    Let $A \in \mathbb{R}^{n \times n}$. Then, $A$ is an almost $P$-matrix of the second category if and only if the following hold:

    \begin{enumerate}
     \item[(a)] $N(A) \cap  \inte (\mathbb{R}_+^n) = \emptyset$, where
 $N(A)$  denotes the null space of $A$,
     \item[(b)] $x_i(Ax)_i \leq 0$ for all $i$ implies that $x =0$, if  $x_k =0$ for some $k$; otherwise $x > 0 $ or $x <0$,
     \item[(c)] $A (\inte (\mathbb{R}_+^n)) \cap \inte (\mathbb{R}_-^n) \neq \emptyset$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Let $A$ be an almost $P$-matrix of the second category, and $x_i (Ax)_i \leq 0$ for all $i$. Suppose that  $x_k =0$ for some $k$. Let $B$ be the principal submatrix of $A$ obtained by deleting the $k$-th row and the $k$-th column of $A$. Let $y$ be the $(n-1)$-vector obtained from the vector $x$ by deleting the $k$-th entry. Then  $y_j (By)_j \leq 0$ for all $j$. Since $B$ is a $P$-matrix, so $y_j=0$ for all $j$.  Thus $x =0.$ Suppose that $x_i \neq 0$ for all $i$.  Let $y = Ax$. Then, $y_i(A^{-1}y)_i \leq 0$  for all $i$. Since $A^{-1}$ is an $N$-matrix of the second category, so, by Theorem \ref{PR}, either $y \geq 0$ or $y \leq 0$.  Note that $A^{-1}<0$. Hence, all the components of the vector $x = A^{-1} y$ are   either positive or negative. As $A$ is an almost $P$-matrix of the second category, there exists a positive vector $x$ such that $Ax<0$. Thus $(c)$ holds.

To prove the converse, first let us show that all the proper principal minors are positive.  Let $B$ be any $(n-1) \times (n-1) $ principal submatrix of $A$. Without loss of generality, assume that $B$ is obtained from  $A$ by deleting the last row and the last column of $A$. Let $x \in \mathbb{R}^{n-1}$, and  define $y =  \begin{pmatrix}
            x\\
            0 \\
            \end{pmatrix}  $.
If $x_i(Bx)_i \leq 0$ for all $i$, then $y_i (Ay)_i \leq 0$ for all $i$.
Thus, by the assumption,  $y = 0$, and hence $x =0$. By Theorem
\ref{snrp}, all the proper principal minors of $A$ are positive. We now
claim $A$ is invertible. Indeed, let $x$ be a vector such that $Ax=0$. Then either $x>0$ or $x<0$ or $x=0$. Since $N(A) \cap  \inte (\mathbb{R}_+^n) = \emptyset$, so $x =0$. Also $A$ is not a $P$-matrix, since $A (\inte (\mathbb{R}_+^n)) \cap \inte (\mathbb{R}_-^n) \neq \emptyset$, so $A$ reverses the sign of a nonzero vector. Thus $\det A < 0$, hence $A$ is an almost $P$-matrix. Let $x  = A^{-1} e_i$. %, where $e^i$ denotes the $i$-th standard basis vector.
 Note that the $i$-th entry of the vector $x$ is negative. Now, we have  $x_j (Ax)_j \leq 0$. Thus the vector $x$ is negative, and hence $A^{-1} < 0$. So $A$ is an almost $P$-matrix of the second category.
 \end{proof}


 Using Theorem \ref{alm-p-sec}, we establish an equivalent condition for an  interval hull to be a subset of the set of all almost $P$-matrices of the second category.


\begin{theorem}\label{almst p sec hull}
    Let $A,B \in \mathbb{R}^{n \times n}$. Then $\mathbb{I}(A,B)$ is an almost $P$-matrix of the second category  if and only if $I_u$ and $I_z$ are almost $P$-matrices of the second category for all $z\in \{ \pm 1 \}^n$.
\end{theorem}

\begin{proof}
    Let $\mathbb{I}(A,B)$ be an almost $P$-matrix of the second category.   Thus, by Lemma \ref{int-lem1},  the matrices $I_u$ and $I_z$ are almost $P$-matrices of the second category for all $z\in \{ \pm 1 \}^n$.

    Conversely, suppose that $I_u$ and $I_z$ are almost $P$-matrices of the second category for all $z\in \{ \pm 1 \}^n$. Let $C \in \mathbb{I}(A,B)$. First let us show that $N(C) \cap  \inte (\mathbb{R}_+^n)= \emptyset$. Let $x \in N(C) \cap  \inte (\mathbb{R}_+^n)$. Then $I_ux\geq 0$, since $I_u\geq C$ and $Cx=0$. Since $I^{-1}_u<0$, so $I^{-1}_u(I_ux)=x\leq 0$, a contradiction. Thus $N(C) \cap  \inte (\mathbb{R}_+^n)= \emptyset$.

     Since $I_u$ is an almost $P$-matrix of the second category, there exists a vector $x>0$ such that $I_ux<0$. Thus $Cx<0$, since $I_u\geq C$. Hence $C(\inte (\mathbb{R}_+^n)) \cap \inte (\mathbb{R}_-^n) \neq \emptyset$.

 Let $x \in \mathbb{R}^n$ and  such that $x_i(Cx)_i\leq 0$ for $i \in \langle   n \rangle$. By Lemma \ref{rohn_exten2}, there exists a vector $z\in \{ \pm 1 \}^n$ such that $0\geq x_i (C x)_i \geq x_i(I_z x)_i$ for $i \in \langle   n \rangle$. Since $I_z$ is an almost $P$-matrix of the second category, by Theorem \ref{alm-p-sec}, $x=0$, if $x_k = 0$ for some $k$,  otherwise $x< 0$ or $x>0$. Thus, by Theorem \ref{alm-p-sec}, $C$ is an almost $P$-matrix of the second category.
\end{proof}


For a nonempty proper subset $ J$ of $ \langle n \rangle$, define
\begin{equation}
\mathbb{J} := \{x \in \mathbb{R}^n: x_j > 0  ~\mbox{for all}~ j \in J
~\mbox{and}~ x_j <0 ~\mbox{for all}~ j \notin J  \}.
\end{equation}
Note that if $A$ is an almost $P$-matrix of the first category with respect to $J$, then there exists  $x \in \mathbb{J}$ such that $Ax \in -\mathbb{J}$. Next, we develop the sign non-reversal property for almost $P$-matrices of  the first category with respect to $J$.


 \begin{theorem}\label{alm-p-1st}
 Let $A \in \mathbb{R}^{n \times n}$ and let $J$  be a nonempty proper subset of $ \langle n \rangle$. Then $A$ is an almost $P$-matrix of the first category with respect to $J$ if and only if
the following hold:

 \begin{enumerate}
 	\item[(a)] $N(A) \cap  \mathbb{J} = \emptyset$,
 	\item[(b)] $x \in \mathbb{R}^n$ and $x_i (Ax)_i \leq 0$ for all $i \in \langle n \rangle$ imply $x=0,$ if $x_k=0$  for some $k$; otherwise either $x\in \mathbb{J}$ or $-x \in \mathbb{J}$,
 	\item[(c)] $A (\mathbb{J}) \cap  (-\mathbb{J}) \neq \emptyset$.
 \end{enumerate}
 \end{theorem}
 \begin{proof}
Let $A$ be an almost $P$-matrix of the first category with respect to $J$. Then,
$A^{-1} = \begin{pmatrix}
            B_{JJ} & B_{J J^\complement} \\
B_{J^\complement J} & B_{J^\complement J^\complement}\\
            \end{pmatrix}$, where $B_{JJ} < 0, B_{J J^\complement} >0, B_{J^\complement J} > 0$ and $ B_{J^\complement J^\complement} < 0$. Let  $x_i(Ax)_i \leq 0.$ If $x_i =0$ for some $i$, then, by an  argument similar to that of Theorem \ref{alm-p-sec}, we get $x=0$.  So, let us assume that $x_i \neq 0$ and $x_i(Ax)_i \leq 0$ for each $i$. Let $y=Ax$. Then $y_i(A^{-1}y)_i \leq 0$ for each $i$.    Hence, by Theorem \ref{nmat-fir-char}, $y=
\begin{pmatrix}
            y_{J}\\
            y_{J^\complement}\\
            \end{pmatrix} $ where either $y_J \leq 0$, $y_{J^\complement} \geq 0$ or $y_J \geq 0$, $y_{J^\complement} \leq 0$. Also, $x=A^{-1}y = \begin{pmatrix}
            x_J\\
            x_{J^\complement}\\
            \end{pmatrix} $, so $x_J >0, x_{J^\complement} <0$ or $x_J <0, x_{J^\complement} >0.$ As $A$ is an almost $P$-matrix of the first category with respect to $J$, so there exists  $x \in \mathbb{J}$ such that $Ax \in -\mathbb{J}$. Thus $(c)$ holds true.

Conversely, suppose that $A$ satisfies all the three properties as above. Let $C$ be any $(n-1) \times (n-1) $ principal submatrix of $A$. Without loss of generality, assume $C$ is obtained from  $A$ by deleting the last row and the last column of $A$.
Let $x \in \mathbb{R}^{n-1}.$ Set $y= \begin{pmatrix} x\\ 0\\
\end{pmatrix}.$  If $x_i(Cx)_i \leq 0$ for all $i$, then $y_i
(Ay)_i \leq 0$ for all $i \in \langle n \rangle$. Thus, by assumption $y
= 0$, so $x =0$. Thus all the proper principal minors of $A$ are
positive. Since $N(A) \cap \mathbb{J} = \emptyset$, so $A$ is invertible
by the proof of Theorem \ref{alm-p-sec}. As,  $A (\mathbb{J}) \cap
(-\mathbb{J}) \neq \emptyset$, so the matrix $A$ is not  a $P$-matrix.
Thus  $A$ is an almost $P$-matrix. Let $x=A^{-1}e_k$. Then $x_i
(Ax)_i\leq 0$ for all $i\in \langle n \rangle$. If $k\in J$, then
$(A^{-1}e_k)_J<0$ and $(A^{-1}e_k)_{J^\complement}>0$, since the $k$-th
entry of $x$ is negative. Otherwise $(A^{-1}e_k)_J>0$ and
$(A^{-1}e_k)_{J^\complement}<0$. Hence $A$ is an almost $P$-matrix of the
first category with respect to $J$.
\end{proof}

For a nonempty proper subset $J$ of  $\langle n \rangle$, define the
matrices
\begin{equation}
I_J := {\rm diag}((-1)^{1 (i \not\in J)} : i \in \langle n \rangle), \qquad
I_{P_J}:=I_c + I_J \Delta I_J.
\end{equation}
Also define $I_\emptyset := -{\rm Id}_n$. One can verify that  $I_{P_J}
\in \mathbb{I}(A,B)$.

In the following theorem, we establish  an equivalent condition  for an interval hull to be a subset of the set of all almost $P$-matrices of the first category with respect to $J$.  
\begin{theorem}\label{almost p 1st hull}
 Let $A,B \in \mathbb{R}^{n \times n}$. Then $\mathbb{I}(A,B)$ is an almost $P$-matrix of the first category with respect to $J$ if and only if $I_{P_J}$ and $I_z$ are almost $P$-matrices  of the first category with respect to $J$ for all $z\in \{ \pm 1 \}^n$.
\end{theorem}

\begin{proof}
    Let $\mathbb{I}(A,B)$ be an almost $P$-matrix of the first category with respect to $J$.   Then the matrices $I_{P_J}$ and $I_z$ are almost $P$-matrices of the first category with respect to $J$ for all $z\in \{ \pm 1 \}^n$.

    Conversely, suppose that the matrices $I_{P_J}$ and $I_z$ are almost $P$-matrices of the first category with respect to $J$  for all $z\in \{ \pm 1 \}^n$. From the definition, $I_{P_J}=\begin{pmatrix}
            {(I_u)}_{JJ} & {(I_l)}_{J J^\complement} \\
            {(I_l)}_{J^\complement J} & {(I_u)}_{J^\complement  J^\complement}\\
    \end{pmatrix}$. Let $C \in \mathbb{I}(A,B)$. First let us show that $N(C) \cap  \mathbb{J}= \emptyset$. Let $x \in N(C) \cap  \mathbb{J}$ and $y=I_{P_J}x$. Then  $x_J>0$ and $x_{J^\complement}<0$. Now,  $(I_u)_{JJ} x_{J} + (I_l)_{J J^\complement}x_{J^\complement} \geq  C_{JJ} x_{J} + C_{J J^\complement}x_{J^\complement}$, $(I_l)_{J^\complement J} x_{J} + (I_u)_{J^\complement J^\complement}x_{J^\complement} \leq  C_{J^\complement J} x_{J} + C_{J^\complement J^\complement}x_{J^\complement}$ and $Cx=0$ imply that $y_J\geq0$ and $y_{J^\complement}\leq 0$. Since ${(I^{-1}_{P_J})}_{JJ}<0, {(I^{-1}_{P_J})}_{J^\complement J^\complement} < 0$,  ${(I^{-1}_{P_J})}_{JJ^\complement }>0$ and  $ {(I^{-1}_{P_J})}_{J^\complement J }>0$, so ${(I^{-1}_{P_J}y)}_J=x_J\leq  0$ and ${(I^{-1}_{P_J}y)}_{J^\complement}=x_{J^\complement} \geq 0$, a contradiction. Thus $N(C) \cap  \mathbb{J}= \emptyset$.

    Since $I_{P_J}$ is an almost $P$-matrix of the first category with respect to $J$, there exists a vector $x\in \mathbb{J}$ such that ${(I_{P_J}x)}_J<0$ and ${(I_{P_J}x)}_{J^\complement}>0$. Thus ${(Cx)}_J<0$ and ${(Cx)}_{J^\complement}>0$. Hence $C (\mathbb{J}) \cap  (-\mathbb{J}) \neq \emptyset$.

     Let $x \in \mathbb{R}^n$ be  such that $x_i(Cx)_i\leq 0$ for $i \in \langle n \rangle$. By Lemma \ref{rohn_exten2}, there exists a vector $z\in \{ \pm 1 \}^n$ such that $0\geq x_i (C x)_i \geq x_i(I_z x)_i$, for $i\in \langle n \rangle$. Since $I_z$ is an almost $P$-matrix of the first category, by Theorem \ref{alm-p-1st}, $x=0$, if $x_k = 0$ for some $k$,  otherwise $x\in \mathbb{J}$ or $x \in -\mathbb{J}$. Hence, by Theorem \ref{alm-p-1st}, $C$ is an almost $P$-matrix of the first category with respect to $J$.
\end{proof}


    \subsection{Semipositive matrices}\label{sec-semi}
In this section we characterize the interval hull for semipositive and minimally semipositive matrices (see Definition \ref{maindefn}).
\begin{theorem}\label{int-semi}
    Let $A,B \in \mathbb{R}^{m \times n}$. Then we have the following:
 \begin{itemize}
        \item[(a)] $\mathbb{I}(A,B)$ is semipositive  if and only if $I_l$ is a semipositive matrix.
        \item[(b)] $\mathbb{I}(A,B)$ is minimally semipositive if and only if $I_l$ is semipositive and $I_u$ is minimally semipositive.
\end{itemize}

\end{theorem}

\begin{proof}
    \textbf{(a)} If $\mathbb{I}(A,B)$ is semipositive, then $I_l$ is also semipositive. Conversely, suppose that $I_l$ is semipositive. Then, there exists $x\geq 0$ such that $I_lx>0$. Let $C \in \mathbb{I}(A,B)$. Then $0< I_l x\leq Cx$. Thus $\mathbb{I}(A,B)$ is semipositive.


    \textbf{(b)} Suppose that $I_l$ is semipositive and $I_u$ is minimally semipositive. Then $\mathbb{I}(A,B)$ is semipositive. Suppose
    $C \in\mathbb{I}(A,B)$ is not minimally semipositive. Then there exists a  nonnegative nonzero vector $x$ with at least one zero entry such that $Cx>0$. Since $I_u\geq C$, so $I_u x>0$, a contradiction. Thus $\mathbb{I}(A,B)$ is minimally semipositive.
\end{proof}

It is known that a square matrix $A$ is minimally semipositive if and
only if $A$ is invertible and $A^{-1}\geq 0$. More generally,  an $m \times n$ matrix $A$ is minimally semipositive  if and only if $A$ is semipositive and $A$ has a nonnegative left inverse \cite{john-ker-stan-semi}. This leads to the following result:

\begin{theorem}[{\cite[Theorem 25.4]{kras-lif-sob}}]\label{kras}
Let $B,C \in \mathbb{R} ^{n \times n}$ such that $C \leq B$, $B$ is
invertible, and $B^{-1}\geq 0$.
Then $C^{-1} \geq 0$ if and only if $\inte(\mathbb{R}_+^n) \cap C\mathbb{R}_+^n \neq \emptyset$.
\end{theorem}

Indeed, in \cite{kras-lif-sob}, the authors proved the above theorem for
any normal and solid cone in $\mathbb{R}^n$. Now, it is clear that part
(b) of Theorem \ref{int-semi} is an extension of Theorem \ref {kras} for
rectangular matrices. We also observe that our proof provides an
alternate, simpler, and elementary proof for Theorem \ref{kras}.

\section{Acknowledgement} We thank Apoorva Khare for a detailed reading
of an earlier draft and for providing valuable comments and feedback.
Projesh Nath Choudhury  is partially supported by National Post-Doctoral
Fellowship(PDF/2019/000275), from SERB, Department of Science and
Technology, India,  and by NBHM Post-Doctoral Fellowship
(0204/11/2018/R$\&$D-II/6437) from DAE (Govt. of India). M. Rajesh Kannan
would like to thank  the SERB, Department of Science and Technology,
India, for financial support through the projects  MATRICS
(MTR/2018/000986) and Early Career Research Award (ECR/2017/000643).

\bibliographystyle{plain}
\bibliography{pro-raj}
\end{document}
