\documentclass[11pt]{amsart}
\usepackage{paper}
\parindent 0in
\usepackage[color=yellow!40]{todonotes}

\title[Norm Form Equations and Linear Divisibility Sequences]{Norm Form Equations and \\ Linear Divisibility Sequences}

\author{Elisa Bellah}


\begin{document}
\begin{abstract}
Finding integer solutions to norm form equations is a classic Diophantine problem. Using the units of the associated coefficient ring, we can produce sequences of solutions to these equations. It turns out that these solutions can be written as tuples of linear homogeneous recurrence sequences, each with characteristic polynomial equal to the minimal polynomial of our unit. We show that for certain families of norm forms, these sequences are linear divisibility sequences. 
\end{abstract}



\maketitle

%------------------- 1. Introduction ---------------------------
\section{Introduction}
Let $K$ be a number field, and $W=\{w_1, \dots, w_n\}$ a $\Q$-linearly independent subset of $K$. The \textit{norm form} associated to the set $W$ is the rational form defined by $F_W(X_1, \dots, X_n):=N_K(X_1w_1+\cdots+X_nw_n).$  Given a norm form $F_W$, it is a classic Diophantine problem to ask for integer solutions to equations of the form
\begin{equation}\label{normform}
F_W(X_1, \dots, X_n)=c,
\end{equation}
where $c$ is a fixed nonzero integer. For example, if $K=\Q(\sqrt{D})$ is real quadratic and $W=\{1, \sqrt{D}\}$, then $F_W(X, Y)=X^2-DY^2$. In this case, we see that (\ref{normform}) is a Pell equation. Note that when $W$ is an integral basis for $K$, the set of solutions to (\ref{normform}) with $c =\pm 1$ gives a complete list of units in $K$. So, the problem of finding units in a number field can be interpreted as such a Diophantine problem.\\

Given a norm form $F_W$, let $M$ be the $\Z$-module in $K$ generated by $W$. Observe that if $T$ is another basis for $M$, the norm forms $F_W$ and $F_T$ are integrally equivalent. So, integer solutions to (\ref{normform}) can be found by instead studying the elements in the associated module $M$ of fixed norm $c$. Let $\O_M:=\{\alpha \in K \mid \alpha M \subseteq M\}$ denote the \textit{coefficient ring} of the module $M$. 
It is well-known that when the module $M$ is full in $K$ (that is, when $\rank M =[K: \Q]$)  the set of elements in $M$ of fixed norm $c$ can be written as a disjoint union of finitely many families
\[\alpha_1\, \U_M^{+}, \dots, \alpha_{\ell}\, \U_M^{+},\]
where $\U_M^+ := \{\epsilon \in \O_M \mid N_K(\epsilon)=1\}$
denotes the \textit{positive unit group} of $M$ (see Chapter 2 of \cite{borevich}, for example). A similar characterization holds in the case 
where $M$ is not full. In \cite{schmidt}, Schmidt showed that the elements in $M$ of fixed norm $c$ can be written as the disjoint union of finitely many families
\[\alpha_{i1} \, \U_{N_i}^{+}, \dots, \alpha_{i \ell}\, \U_{N_i}^{+},\]
where $N_i$ are full modules contained in finitely many subfields $L_i$ of $K$. So, in both the full and non-full cases, our solutions lie in finitely many families of the form $\alpha \, \U^+$, where $\,\U^+$ denotes the positive unit group of an order either in $K$ or a subfield of $K$. Dirichlet's unit theorem applies in the setting, and so we know that these sets are in fact finitely generated abelian groups. However, finding explicit generators for these groups is generally quite challenging. In \cite{schmidt2}, Schmidt obtained explicit bounds for solutions to norm form equations in the case where the corresponding positive unit groups  $\,\U^+$ are all finite (that is, when rank$(\U^+)=0$), but little explicit information is known in the case where $\,\U^+$ has positive rank.\\

Suppose that for one of our families $\alpha \, \U^+$ we have $\rank(\U^+)>0$. Let $\epsilon$ be an element in the free part of $\,\U^+$, and suppose that $\beta$ is an element in $M$ with $N_K(\beta)=c$. Since $\epsilon$ has infinite order, and $N_K(\epsilon)=1$, then we can generate an infinite sequence of elements in $M$ of fixed norm $c$, given by $\alpha(k)=\beta\epsilon^k$, where $k \in \Z_{\geq 0}$. So, if we write
$\alpha(k)=x_1(k) w_1+\cdots+x_n(k) w_n,$
then we obtain infinitely many solutions $(x_1(k), \dots, x_n(k))$ to (\ref{normform}). Furthermore, the characterization above says that all solutions to (\ref{normform}) are obtained in this way.\\

We say that a linear recurrence sequence $b(k)$ is a \textit{linear divisibility sequence} (LDS) if $b(k)$ has the following property: for all $n, m \in \Z_{> 0}$,
\[ n \mid m \Rightarrow b(n) \mid b(m).\]
Divisibility sequences have been widely studied. Oftentimes, this extra structure is helpful in understanding further number theoretic properties of a given sequence. For example, every Lucas sequence is a LDS. This property was used in \cite{BHV} to study the primitve divisors of Lucas sequences, and in \cite{smyth} to study their index divisibility sets, as well as in many other results throughout the literature. Elliptic Divisibility Sequences, introduced by Ward in \cite{ward}, are examples of nonlinear divisibility sequences. Similar results for these sequences have also been found, such as in \cite{stangesilverman} and \cite{EDSprimdivs}.\\


In this paper, we show that for certain families of norm forms, the sequences $x_i(k)$ are linear divisibility sequences. In particular, we prove the following.

\begin{prop} \label{mainprop} Let $K$ be a real quadratic field and $M$ a full module in $K$. Fix an element $\beta \in M$ and write $\alpha(k)=\beta \epsilon^k$. Then, for any $i \in \{1, 2\}$, there is a choice of basis $W=\{w_1, w_2\}$ for $M$ so that if we write
\[\alpha(k)=x_1(k)w_1+x_2(k)w_2\]
then the sequence $x_i(k)$ is a LDS. 
\end{prop}

Proposition \ref{mainprop} follows from known results on order 2 linear recurrence sequences. The main results of this paper provide new examples of order 4 linear divisibility sequences by considering norm forms over certain quartic extensions. We will show the following.

\begin{thm} \label{thm1} Let $K$ be a quartic field with real quadratic subfield $L$ containing a quartic unit of the form $\eta=\sqrt{\epsilon}$, where $\epsilon$ is a unit in $L$ of positive norm. Fix an element $\beta \in K$, and write $\alpha(k)=\beta \eta^k$. Then, for any $i \in \{1, \dots, 4\}$ there is a choice of basis  $W=\{w_1, \dots, w_4\}$ for the module $M'=\beta \,\Z[\eta]$ so that if we write
\[\alpha(k)=x_1(k)w_1+\cdots+x_4(k)w_4\]
then $x_i(k)$ is a LDS.
\end{thm}

\begin{thm}\label{thm2}   Let $M=\Z[\sqrt{m}, \sqrt{n}]$, where $m$ and $n$ are non-square integers with $n=m+1$. Then, $\eta=\sqrt{m}+\sqrt{n}$ is a unit in $\U_M^+$ of the form $\eta=\sqrt{\epsilon}$, and for any $i \in \{1, \dots, 4\}$ there is a choice of basis $W=\{w_1, \dots, w_4\}$ for the module $M$ so that if we write
\[\eta^k=x_1(k)w_1+\cdots+x_4(k)w_4,\]
then $x_i(k)$ is a LDS. 
\end{thm}


This paper is organized as follows. In Section 2, we show that the sequences $x_i(k)$ are linear recurrence sequences, each with characteristic polynomial equal to the minimal polynomial of our unit. In Section 3, we provide some background on Lucas sequences, and use this to prove Proposition \ref{mainprop}. In Section 4, we prove Theorems \ref{thm1} and \ref{thm2}.



%------------------- 2. Coordinate Sequences ---------------------------
\section{Coordinate Sequences}
Let $M$ be a full module in a number field $K$, and $\epsilon$ a unit in the free part of $\U_M^+$. Suppose that $\beta \in M$ with $N_K(\beta)=c$. As in the introduction, set $\alpha(k)=\beta \epsilon^k$. If we choose a basis $W=\{w_1, \dots, w_n\}$ for $M$, and write
\[\alpha(k)=x_1(k)w_1+\cdots+x_n(k)w_n,\]
then we obtain tuples of solutions $(x_1(k), \dots, x_n(k))$ to the corresponding norm form equation $F_W(X_1, \dots, X_n)=c$. 

\begin{mydef} We call the integer sequences $x_i(k)$ the \textit{coordinate sequences} of $\alpha(k)$ with respect to our choice of basis $W$. 
\end{mydef}

Let $b(k)$ be an integer sequence satisfying the linear homogeneous recurrence
\begin{equation} \label{recurrence} b(k+d)=s_1b(k+d-1)+\cdots+s_db(k), \end{equation}
where $s_i \in \Z$. Then, the \textit{characteristic polynomial} for this recurrence is given by $f(X)=X^d-s_1X^{d-1}-\cdots-s_d.$ 
When recurrence (\ref{recurrence}) is of minimal order, $f(X)$ is called the \textit{minimal polynomial} of the sequence $b(k)$. In this section, we show that the coordinate sequences $x_i(k)$ have characteristic polynomial equal to the minimal polynomial of $\epsilon$. We also provide sufficient conditions so that the minimal polynomial of the sequence $x_i(k)$ is equal to the minimal polynomial of $\epsilon$. 

\begin{prop} \label{prop1} Let $K$ be a number field, and take elements $\gamma, \theta \in K$. Consider the sequence
$x(k)=\Tr_K(\gamma \theta^k).$ Then, $x(k)$ satisfies a linear homogeneous recurrence with characteristic polynomial equal to the minimal polynomial of $\theta$. Furthermore, let $\sigma_1, \dots, \sigma_n$ denote the embeddings $K \hookrightarrow \C$ fixing $\Q$. If there exists an $i \in \{1, \dots, n\}$ so that
\[\Tr_{L_i}^{K_i}(\gamma) \not=0,\]
where $L_i=\Q(\sigma_i(\theta))$ and $K_i=\sigma_i(K)$, then the minimal polynomial of the sequence $x(k)$ is equal to the minimal polynomial of $\theta$.
\begin{proof}
Let $\gamma_i:=\sigma_i(\gamma)$ and $\theta_i:=\sigma_i(\theta)$, for $i \in \{1, \dots, n\}$. Suppose that $\theta$ has minimal polynomial over $\Q$ given by $f(X)=X^d-s_1X^{d-1}-\cdots-s_d.$
Then, we can write
\[x(k)=\Tr_K(\gamma \theta^k)=\sum_{i=1}^n \gamma_i \theta_i^k.\]
So, we have 
\begin{align*}
\sum_{j=1}^d s_j x(k+d-j)	&= \sum_{j=1}^d \sum_{i=1}^n s_j \gamma_i \theta_i^{k+d-j} \\
					&=\sum_{i=1}^n \gamma_i \theta_i^k \sum_{j=1}^d s_j \theta_i^{d-j} \\
					&=\sum_{i=1}^n \gamma_i \theta_i^k \theta_i^d,
\end{align*}
where the final equality follows because each $\theta_i$ is a root of $f(X)$. So, our sequence satisfies the recurrence $x(k+d)=\sum_{j=1}^d s_jx(k+d-j),$ which has characteristic polynomial equal to $f(X)$. Next, suppose that $x(k)$ satisfies an order $m$ recurrence for $0 < m \leq d$, say
\[x(k+m)= \sum_{j=1}^{m} r_j x(k+m-j),\]
where $r_j \in \Z$. Then, we have
\[\Tr_K(\gamma \theta^{k+m})=\sum_{j=1}^m r_j \Tr_K(\gamma \theta^{k+m-j}),\]
and by linearity of the trace, we get $\Tr_K(C \theta^k \cdot \gamma)=0,$
where \[C=\theta^m-\sum_{i=1}^m r_i \theta^{m-i}.\] 
Order the embeddings so that $\sigma_1(\theta)=\theta_1, \dots, \sigma_d(\theta)=\theta_d$ are distinct. Since $\Tr_K(C \theta^k \cdot \gamma)=0$ for every $k \in \Z_{\geq 0}$ we get
\begin{equation}
\label{matrices}
\begin{pmatrix} \sigma_1(C \theta^0) & \cdots & \sigma_d(C \theta^0) \\ \vdots & \ddots & \vdots \\ \sigma_1(C \theta^{d-1}) & \cdots & \sigma_d(C \theta^{d-1}) \end{pmatrix} 
\begin{pmatrix} \Tr_{L_1}^{K_1}(\gamma) \\ \vdots \\ \Tr_{L_d}^{K_d}(\gamma)\end{pmatrix}= \begin{pmatrix} 0 \\ \vdots \\ 0 \end{pmatrix},\end{equation}
where $L_i=\Q(\theta_i)$ and $K_i=\sigma_i(K)$. Now, if $C \not=0$ then the set $\{C, C\theta, \dots, C\theta^{d-1}\}$ is $\Q$-linearly independent, and so
\[\det \begin{pmatrix} \sigma_1(C \theta^0) & \cdots & \sigma_n(C \theta^0) \\ \vdots & \ddots & \vdots \\ \sigma_1(C \theta^{d-1}) & \cdots & \sigma_d(C \theta^{d-1}) \end{pmatrix} =\disc(C, \theta, \dots, C\theta^{d-1})^{1/2} \not=0.\]
Suppose that $\Tr_{L_i}^{K_i}(\gamma)\not=0$ for some $i \in \{1, \dots, d\}$. Then, by (\ref{matrices}) we have $C=0$. So, $\theta$ is a root of the polynomial
\[X^m-\sum_{i=1}^m r_i X^{m-i} \in \Z[X]\]
But since $\theta$ is degree $d$, and $m \leq d$ we get $m=d$. Hence, the recurrence
\[x(k+d)=\sum_{j=1}^d s_j x(k+d-j)\]
is minimal, and so $f(X)$ is the minimal polynomial of the sequence $x(k)$.
\end{proof} 
 \end{prop}


\begin{rmk} The statement that $x(k)$ is a linear recurrence sequence of order at most $[K: \Q]$ can be found in Chapter 1 of \cite{recurrence}. However, there does not appear to be a complete characterization for when the sequence $x(k)$ is exactly of order $\deg\theta$ in the current literature. It would be interesting to provide such a characterization.\\

Note that it is possible for $x(k)$ to have a smaller order than $\deg \theta$. For example, take $K=\Q(\sqrt{2}, \sqrt{3}, \sqrt{5})$, $\theta=\sqrt{2}+\sqrt{3}$ and $\gamma=\sqrt{5}$. Then, if $x(k)=\Tr_K(\gamma \theta^k)$, we can check that $x(k)=0$ for $k=0, 1, 2, 3$. Using Proposition \ref{prop1}, we know that $x(k)$ satisfies a recurrence of order 4. Since the initial values are all zero, this sequence is identically zero. 
\end{rmk}

We have the following Corollary to Proposition \ref{prop1}.

\begin{cor} \label{cor1} Let $K$ be a number field and $M$ a full module in $K$. Suppose that $\epsilon$ is a unit in the free part of $\,\U_M^+$. For a fixed $\beta \in M$, let $\alpha(k)=\beta \epsilon^k$, and $x(k)$ be a coordinate sequence of $\alpha(k)$ with respect to some basis. Then, $x(k)$ is a linear homogeneous recurrence sequence with characteristic polynomial equal to the minimal polynomial of $\epsilon$. Furthermore, if $\deg\epsilon=[K: \Q]$ then the minimal polynomial of the sequence $x(k)$ is equal to the minimal polynomial of $\epsilon$.
\begin{proof}
Let $W=\{w_1, \dots, w_n\}$ be any basis for $M$, and write
\[\alpha(k)=x_1(k)w_1+\cdots+x_n(k)w_n.\]
Since $M$ is a full module, $W$ is a $\Q$-basis for $K$. So, there exists a dual basis $W^*=\{w_1^*, \dots, w_n^*\}$ to $W$ with respect to the trace pairing. That is, $W^*$ is a basis for $K$, and we have $\Tr_K(w_i^* w_j)=\delta_{ij}$
for all $i, j$. Let $\gamma=w_i^* \beta$. Then we have $x_i(k)=\Tr_K(\gamma \epsilon^k)$. Note that if $\deg \epsilon=[K: \Q]$ then $\Q(\theta)=K$. So \[\Tr_{\Q(\theta)}^K(\gamma)=\gamma\not=0.\] 
Hence, the result follows from Proposition \ref{prop1}.
\end{proof}
\end{cor}


%------------------- 3.Quadratic Extensions ---------------------------

\section{Norm Form Equations over Real Quadratic Fields}

Suppose that $K$ is a real quadratic field, and let $M$ be a full module in $K$. For any $\beta \in M$ and $\epsilon$ in the free part of $\,\U_M^+$, let $\alpha(k)=\beta \epsilon^k$ as before. Since $\epsilon$ is degree 2 over $\Q$, Corollary \ref{cor1} implies that the coordinate sequences of $\alpha(k)$ are order 2 linear homogeneous recurrence sequences. Such sequences have been well-studied, and so Corollary \ref{cor1} implies some immediate consequences. First, we provide the relevant background.\\

Let $P, Q$ be nonzero coprime integers. Then, the \textit{Lucas sequence} with integer parameters $(P, Q)$ is the order 2 linear recurrence sequence $u_k$ with initial values $u_0=0$, $u_1=1,$ and recurrence
\[u_{k+2}=Pu_{k+1}-Qu_k.\]
For example, the Fibonacci sequence is the Lucas sequence with integer parameters $(1, -1)$. Let $\theta, \bar{\theta}$ be roots of the polynomial $X^2-PX-Q$. It is a short exercise to show that the terms of the Lucas sequence with integer parameters $(P, Q)$ satisfies the explicit formula
\[u_k=\frac{\theta^k-\bar{\theta}^k}{\theta-\bar{\theta}}.\]
Note that Lucas sequences are sometimes defined by the parameters $(\theta, \bar{\theta})$, rather than the integer parameters $(P, Q)$.\\

The following elementary Lemma is well-known, but the proof is often not included in the literature. We provide a short proof for completeness. 
\begin{lem}\label{LucasDivisibility} Every Lucas sequence is a LDS. 
\begin{proof}
Let $P, Q$ be nonzero coprime integers, and consider the matrix
\[A=\begin{pmatrix} P & -Q \\ 1 & 0 \end{pmatrix}.\]
Observe that for any positive integer $k$, we have
\[A^k=\begin{pmatrix} u_{k+1} & -Q u_k \\ u_k & -Q u_{k-1} \end{pmatrix},\]
where $u_k$ is the Lucas sequence with integer parameters $(P, Q)$. Now, take any positive integers $m, n$. Then we have
\[A^{mn}=\begin{pmatrix} u_{m+1} & -Q u_m \\ u_m & -Qu_{m-1} \end{pmatrix}^n \equiv \begin{pmatrix} * & * \\ 0 & * \end{pmatrix} (\mod u_m).\]
On the other hand, we have
\[A^{mn}=\begin{pmatrix} u_{mn+1}  & -Q u_{mn} \\ u_{mn} & -Q u_{mn-1} \end{pmatrix}.\]
Comparing the lower left hand entires, we see that $u_m \mid u_{mn}$
for every $m, n \in \Z_{>0}$. So, $u_k$ is a LDS. 
\end{proof}
\end{lem}

We are now prepared to prove our first result.

\subsection*{Proof of Proposition \ref{mainprop}} Without loss of generality, let $i=1$. By Lemma \ref{LucasDivisibility}, it suffices to find a basis $\{w_1, w_2\}$ for $M$ so that $x_1(0)=0$. Choose any basis $\{t_1, t_2\}$ for $M$, and let $B$ be the matrix given by
\[\begin{pmatrix} \beta \\ \beta \epsilon \end{pmatrix}=B \begin{pmatrix} t_1 \\ t_2\end{pmatrix}.\]
Note that $\exists C \in \GL_2(\Z)$ so that $BC$ is lower triangular. So, we can define a new basis $\{v_1, v_2\}$ from $\{t_1, t_2\}$ by change of basis matrix $C^{-1}$. Then,
\begin{equation}\label{quadmatrix1}
 \begin{pmatrix} \beta \\ \beta \epsilon \end{pmatrix}=\begin{pmatrix} a_{11} & 0 \\ a_{21} & a_{22} \end{pmatrix} \begin{pmatrix} v_1 \\ v_2 \end{pmatrix},
\end{equation}
for some $a_{ij} \in \Z$. Now, let $W=\{w_1, w_2\}$ be the basis defined by
\[\begin{pmatrix} w_1 \\ w_2 \end{pmatrix} =\begin{pmatrix} 1 & 1 \\ 1 & 0 \end{pmatrix} \begin{pmatrix} v_1 \\ v_2\end{pmatrix}.\]
We claim that we can take $W$ as our desired basis. To see this, observe that
\[ \begin{pmatrix} 0 & a_{11} \\ a_{22} & a_{21}-a_{22} \end{pmatrix} \begin{pmatrix} w_1 \\ w_2 \end{pmatrix} =
\begin{pmatrix} a_{11} & 0 \\ a_{21} & a_{22} \end{pmatrix} \begin{pmatrix} v_1 \\ v_2 \end{pmatrix}.\]
So, if we write $\alpha(k)=x_1(k)w_1+x_2(k)w_2$ then by (\ref{quadmatrix1}) $x_1(k)$ has initial conditions $x_1(0)=0$ and $x_1(1)=a_{22}$. So, $x_1(k)=a_{22} u_k$, where $u_k$ is the Lucas sequence with parameters $(\epsilon, \bar{\epsilon})$. By Corollay \ref{cor1} we know that $x_1(k)$ is an order 2 recurrence sequence, and so we must have $a_{22}\not=0$. Hence, $x_1(k)$ is a LDS. \hfill $\qed$



%------------------- 4. Biquadratic Extensions ---------------------------
\section{Norm Form Equations over Quartic Fields}
Let $K$ be a quartic field, and $M$ a full module in $K$. Choose any $\beta \in M$, and suppose there exists a unit $\eta \in \U_M^+$ of degree 4 over $\Q$. By Corollary \ref{cor1}, the coordinate sequences of $\alpha(k)=\beta \eta^k$ are order 4 linear recurrence sequences. Unlike in the order 2 case, much less is known about higher-order linear recurrence sequences, and so it is generally quite challenging to determine when an arbitrary order 4 linear recurrence sequence is a LDS. \\

We instead restrict our attention to modules containing units of the form $\eta=\sqrt{\epsilon}$ where $\epsilon$ is real quadratic unit. In \cite{kuroda}, Kurodo showed that there exists infinitely many biquadratic fields containing units $\eta$ of this form, and furthermore that all units in a biquadratic field $K$ are completely determined by the units in its quadratic subfields. \\

Observe that when $\eta=\sqrt{\epsilon}$ is of degree 4 over $K$, $\eta$ has minimal polynomial $f(X)=X^4-\Tr_K(\epsilon)X^2+1$. So, Corollary \ref{cor1} implies that the coordinate sequences $x(k)$ of $\alpha(k)$ are order 4 linear recurrence sequences satisfying
\begin{equation}
\label{order4rec} x(k+4)=\Tr_K(\epsilon)x(k+2)-x(k).
\end{equation}
The following Proposition gives sufficient initial conditions for $x(k)$ to be a LDS, and will be used to prove our main results. 

\begin{prop} \label{prop} Let $x(k)$ be an order 4 linear recurrence sequence with initial conditions
$x(0)=0, \, x(1)=x(2)=a, \, x(3)=a(T+1),$
and recurrence $x(k+4)=Tx(k+2)-x(k)$, where $a$ and $T$ are nonzero integers. Then, $x(k)$ is a LDS. 
\begin{proof} Note that it suffices prove our claim for $a=1$. 
Let $u_k$ denote the Lucas sequence with integer parameters $(T, 1)$. Since we assumed that $x(0)=0$ and $x(2)=1$, we have $x(2n)=u_n$ for every $n \in \Z_{\geq 0}$. Consider the matrix
\[A=\begin{pmatrix} T & -1 \\ 1 & 0 \end{pmatrix}.\]
Recall from the proof of Lemma \ref{LucasDivisibility} that we have the identity
\begin{equation} \label{identity0} A^n=\begin{pmatrix} u_{n+1}	& - u_n \\ u_n & -u_{n-1} \end{pmatrix},
\end{equation}
and so we have
\begin{equation} \label{identity1}
A^n= \begin{pmatrix} x(2n+2) & -x(2n) \\ x(2n) & -x(2n-2) \end{pmatrix},
\end{equation}
for every $n \in \Z_{>0}$. Using the recurrence for $x(k)$, we observe that
\begin{equation} \label{identity2}
A^n \begin{pmatrix} x(3) \\ x(1) \end{pmatrix}=\begin{pmatrix} x(2n+3) \\ x(2n+1) \end{pmatrix}.
\end{equation}
Combining (\ref{identity1}) and (\ref{identity2}) yields
\[\begin{pmatrix} x(2n+3) \\ x(2n+1) \end{pmatrix} = \begin{pmatrix} x(3)x(2n+2) -x(1)x(2n) \\ x(3)x(2n)-x(1)x(2n-2) \end{pmatrix}.\]
That is, we have $x(2n+1)=x(3)x(2n)-x(1)x(2(n-1))$ for any positive integer $n$. Recalling that $x(1)=1,$ $x(3)=T+1$ and $x(2n)=u_n$, we obtain
\begin{align*}
x(2n+1)	&=(T+1)u_n-u_{n-1}\\
		& =u_{n+1} +u_n,
\end{align*}
where the final equality follows by using the recurrence for $u_k$. So, we have
\[x(k)=\begin{cases} u_n, & \text{ if } k=2n \\ u_{n+1}+u_{n}, & \text{ if } k=2n+1, \end{cases}\]
for any $k \in \Z_{\geq 0}$. 
Note that we need to show $x(k) \mid x(k\ell)$ for every $k, \ell \in \Z_{\geq 0}$. Suppose that $k=2n$. Then, $x(k)=u_n$ and $x(k\ell)=u_{n\ell}$. So, by Lemma \ref{LucasDivisibility} we have $x(k) \mid x(k \ell)$. Next, suppose that $k=2n+1$ and $\ell=2m$.
Noting that $A^{2n}=(A^n)^2$, and using identity (\ref{identity0}) we have
\[\begin{pmatrix} u_{2n+1} & -u_{2n} \\ u_{2n} & - u_{2n-1} \end{pmatrix}=\begin{pmatrix} u_{n+1} & -u_n \\ u_n & -u_{n-1} \end{pmatrix}^2.\]
Comparing the upper left-hand entries yields the identity
$
u_{2n+1}=u^2_{n+1}-u_n^2
$
So, we have
\begin{align*}
\frac{x(2k)}{x(k)}	&=\frac{x(2(2n+1))}{x(2n+1)}\\
			&=\frac{u_{2n+1}}{u_{n+1}+u_n}\\
			&=u_{n+1}- u_{n} \in \Z.
\end{align*}
Hence, $x(k) \mid x(2k)$, and by the previous case we have
\[x(2k) \mid x(2km) \Rightarrow x(k) \mid x(k\ell).\] 
Now, suppose that $k=2n+1$ and $\ell=2m+1$. Let $\epsilon, \bar{\epsilon}$ denote the roots of $X^2-TX+1$. Recall from Section 3 that we can write
\[u_k=\frac{\epsilon^k - \bar{\epsilon}^k}{\epsilon-\bar{\epsilon}},\]
for every $k \in \Z_{\geq 0}$. So, we have
\begin{align*}
x(2n+1)	& =  u_{n+1}+u_{n}\\
		&= \frac{\epsilon^{n+1}-\bar{\epsilon}^{n+1}}{\epsilon -\bar{\epsilon}} + \dfrac{\epsilon^n - \bar{\epsilon}^n}{\epsilon-\bar{\epsilon}}\\
		&= \frac{\epsilon^n(\epsilon+1)-\bar{\epsilon}^n(\bar{\epsilon}+1)}{\epsilon-\bar{\epsilon}}\\
		&= \frac{\epsilon^n(\epsilon+1)-\dfrac{1}{\epsilon^{n+1}} (1+\epsilon)}{\epsilon-\bar{\epsilon}}\\
		&=\frac{\epsilon+1}{\epsilon-\bar{\epsilon}} \cdot \frac{\epsilon^{2n+1}-1}{\epsilon^{n+1}}.
\end{align*}

This gives
\begin{align*}
\frac{x((2n+1)(2m+1))}{x(2n+1)}	&= \frac{x(2(2nm+n+m)+1)}{x(2n+1)}\\
						&= \frac{\epsilon^{2(2nm+n+m)+1}-1}{\epsilon^{2nm+n+m+1}} \cdot \frac{\epsilon^{n+1}}{\epsilon^{2n+1}-1}\\
						&=\frac{\epsilon^{(2n+1)(2m+1)}-1}{\epsilon^{2n+1}-1} \cdot \frac{1}{\epsilon^{m(2n+1)}}.
\end{align*}
To see this value is in $\Z$, let $\alpha=\epsilon^{2n+1}$. Then, from above we obtain
\begin{align*}
\frac{x((2n+1)(2m+1))}{x(2n+1)} &= \frac{\alpha^{2m+1}-1}{\alpha-1} \cdot \frac{1}{\alpha^m}\\
					&=\frac{\alpha^{2m}+\alpha^{2m-1}+\cdots+\alpha+1}{\alpha^m}\\
					&= (\alpha^m+\alpha^{-m})+\cdots+(\alpha+\alpha^{-1})+1.
\end{align*}
Since $\alpha=\epsilon^{2n+1}$ and $N_K(\epsilon)=1$, then $\alpha$ and $\alpha^{-1}$ are quadratic conjugates. So, we have
$\alpha^t+\alpha^{-t} \in \Z$
for every $t=1, \dots, m$. Hence, \[x(2n+1) \mid x((2n+1)(2m+1)),\] and so $x(k)$ is a LDS.
\end{proof}
\end{prop}

Theorem \ref{thm1} will now follow quickly from Proposition \ref{prop1}. Recall that $K$ is a quartic number field with real quadratic subfield $L$ containing a quartic unit of the form $\eta=\sqrt{\epsilon}$, where $\epsilon$ is a unit in $L$ of positive norm.


\subsection*{Proof of Theorem \ref{thm1}}
Without loss of generality, suppose that $i=1$. 
Note that the module $M'=\beta\Z[\eta]$ has basis $\{\beta, \beta \eta, \beta \eta^2, \beta \eta^3\}$. Define the set $W=\{w_1, \dots, w_4\}$ by
\[\underbrace{\begin{pmatrix} 0 & 0 & 1 & 0 \\ 1 & 0 & 0 & 1 \\ 1 & 0 & 0 & 0 \\ \Tr_K(\epsilon)+1 & 1 & 0 & 0 \end{pmatrix}}_{A} \begin{pmatrix} w_1 \\ w_2 \\ w_3 \\ w_4 \end{pmatrix} = \begin{pmatrix} \beta \\ \beta \eta \\ \beta \eta^2 \\ \beta \eta^3 \end{pmatrix}.\]
Note that $A \in \GL_4(\Z)$, and so $W$ is a basis for $M$. 
Since $\eta$ has minimal polynomial $f(X)=X^4-\Tr_K(\epsilon)X^2+1$, then by Corollary \ref{cor1} we know that the sequence $x_1(k)$ is an order 4 linear recurrence sequence satisfying (\ref{order4rec}). Moreover, if we write $\alpha(k)$ in terms of the basis $W$, then 
\[x_1(0)=0, \,x_1(1)=x_2(1)=1, \text{ and } x_3(1)=\Tr_K(\epsilon)+1.\]
So, by Proposition \ref{prop}, $x_1(k)$ is a LDS. \hfill $\qed$ \\

In the following Corollary, we provide explicit formulas for the coordinate sequences of $\alpha(k)$, with respect to the basis constructed in Theorem \ref{thm1}, in terms of Lucas sequences.

\begin{cor} Let $W=\{w_1, \dots, w_4\}$ be the basis for the module $\beta \Z[\eta]$ constructed in Theorem \ref{thm1}, and $\alpha(k)=\beta \eta^k$ be as above. If we write
\[\alpha(k)=x_1(k)w_1+\cdots+x_4(k)w_4,\]
then for any integer $k \geq 2$ we have\\
\[x_1(k) =\begin{cases} u_n & \text{ if } k=2n \\ u_{n+1}+u_n & \text{ if } k=2n+1, \end{cases}
\hspace{2em} x_2(k)=\begin{cases} 0 & \text{ if } k =2n \\ u_n & \text{ if } k=2n+1,\end{cases}\]
\vspace{0.2em}
\[\hspace{0.75em} x_3(k)=\begin{cases} - u_{n-1}  & \text{ if } k=2n \\ 0 & \text{ if } k=2n+1,\end{cases} 
\hspace{3.5em} x_4(k)=\begin{cases} 0 & \text{ if } k=2n \\ - u_{n-1} & \text{ if } k=2n+1, \end{cases}\]
\vspace{0.25em}

where $u_n$ is the Lucas sequence with parameters $(\epsilon, \bar{\epsilon})$. 

\begin{proof} Let $W$ be the basis constructed in the proof of Theorem \ref{thm1}, and write
\[\alpha(k)=x_1(k)w_1+\cdots+x_4(k)w_4.\]
Recall, by Corollary \ref{cor1} we know that all of the coordinate sequences $x_i(k)$ of $\alpha(k)$ satisfy the order 4 recurrence
\[x_i(k+4)=\Tr_K(\epsilon) x_i(k+2)-x_i(k),\]
and by construction of our basis $W$, these sequences have initial conditions
\begin{center}
\begin{tabular}{c | c c c c}
$k$ 	& $x_1(k)$ 				& $x_2(k)$ 	& $x_3(k)$ 		& $x_4(k)$ 		\\\hline
0	& $0$					& $0$		& $1$			& $0$ 			\\
1	& $1$					& $0$		& $0$			& $1$ 			\\
2	& $1$					& $0$		& $0$			& $0$ 			\\
3	& $\Tr_K(\epsilon)+1$		& $1$		& $0$			& $0$
\end{tabular}
\end{center}

Let $\sigma_1, \dots, \sigma_4$ be the distinct embeddings $K \hookrightarrow \C$ fixing $\Q$, and let 
\[W^*=\{w_1^*, \dots, w_4^*\}\]
be a dual basis to $W$ with respect to the trace pairing on $K$. Recall from the proof of Corollary \ref{cor1} that we can write $x_i(k)=\Tr_K(w_i^* \beta \eta^k)$. Also observe that the conjugates of $\eta=\sqrt{\epsilon}$ are given by $\pm \sqrt{\epsilon}, \pm \sqrt{\bar{\epsilon}}$, where $\bar{\epsilon}$ dentoes the quadratic conjugate of $\epsilon$. So, up to relabeling of the embeddings $\sigma_i$, we have
\[x_i(k)=(\gamma_{i1} +(-1)^k\gamma_{i2}) \sqrt{\epsilon}^k+(\gamma_{i3}+(-1)^k\gamma_{i4}) \sqrt{\bar{\epsilon}}^{\,k},\]
for every $k \in \Z_{\geq 0}$, where $\gamma_{ij}=\sigma_j(w_i^*\beta)$. \\

From the proof of Proposition \ref{prop} we see that $x_1(k)$ satisfies the desired formula. Next, since $x_2(0)=x_2(2)=0$, then using the recurrence for $x_2(k)$ above, we see that $x_2(2n)=0$ for every $n \in \Z_{\geq 0}$. We have
\[x_2(2n+1)=(\gamma_{21}-\gamma_{22})\sqrt{\epsilon}^{2n+1}+(\gamma_{23}-\gamma_{24})\sqrt{\bar{\epsilon}}^{\, 2n+1}.\]
Since $x_2(1)=0$ and $N_L(\epsilon)=\epsilon \bar{\epsilon}=1$, we get
$\gamma_{23}-\gamma_{24}= -(\gamma_{21}-\gamma_{22}) \epsilon$. So,
\[x_2(2n+1)=(\gamma_{21} - \gamma_{22}) \left(\sqrt{\epsilon}^{2n+1} - \sqrt{\bar{\epsilon}}^{\, 2n-1}\right).\]
Using the equality above and the fact that $x_2(3)=1$, we have
\[\gamma_1-\gamma_2=\dfrac{1}{\sqrt{\epsilon}^3-\sqrt{\bar{\epsilon}}}\]
which implies that
\[x_2(2n+1)	=\frac{\sqrt{\epsilon}^{2n+1} - \sqrt{\bar{\epsilon}}^{\, 2n-1}}{\sqrt{\epsilon}^3-\sqrt{\bar{\epsilon}}}= \frac{\epsilon^n-\bar{\epsilon}^n}{\epsilon-\bar{\epsilon}},\]
and so $x_2(2n+1)=u_n$, which gives the desired formula for $x_2(k)$. Next, since $x_3(1)=x_3(3)=0$, then using the recurrence for $x_3(k)$, we see that $x_3(2n+1)=0$ for every $k \in \Z_{\geq 0}$. We have
\[x_3(2n)=(\gamma_{31}+\gamma_{32}) \epsilon^n + (\gamma_{33}+\gamma_{34}) \bar{\epsilon}^{\, n}.\]
Since $x_3(2)=0$, we get
\[\gamma_{33}+\gamma_{34}=-(\gamma_{31}-\gamma_{32}) \epsilon^2\]
and so
$x_3(2n)=(\gamma_1+\gamma_2)(\epsilon^n - \bar{\epsilon}^{\,n-2}).$
Since $x_3(0)=1$ and $x_3(2)=0$, we have $x_3(4)=-1$, and so
\[\gamma_{31}+\gamma_{32}=\frac{-1}{\epsilon^2-1}.\]
So, as long as $n \geq 1$, we have
\[x_3(2n)=- \frac{\epsilon^n-\bar{\epsilon}^{\, n-2}}{\epsilon^2-1}=- \frac{\epsilon^{n-1} - \bar{\epsilon}^{\, n-1}}{\epsilon-\bar{\epsilon}}\]
and so $x_2(2n)=u_{n-1}$, which gives the desired formula for $x_2(k)$. We note that the formula for $x_4(k)$ follows similarly to $x_2(k)$, and so we leave this case to the reader.
\end{proof}
\end{cor}

\begin{rmk} Let $M$ be an abitrary full module in our quartic field $K$ and let $\alpha(k)=\beta \eta^k$ as above. Note that $M'=\beta \Z[\eta]$ is a finite index submodule of $M$ containing $\alpha(k)$ for every $k \in \Z_{\geq 0}$. So, we can always write the coordinate sequences for $\alpha(k)$ in terms of the basis constructed in Theorem \ref{thm1}. It turns out to be more challenging to apply Proposition \ref{prop} to find a basis for the entire module $M$. The following Proposition provides a characterization for when this can be done. \end{rmk}

First, we set some notation. For a basis $\{t_1, \dots, t_4\}$ of $M$, write
\[\begin{pmatrix} \beta \\ \beta \eta \\ \beta \eta^2 \\ \beta\eta^3 \end{pmatrix} = B \begin{pmatrix} t_1 \\ t_2 \\ t_3 \\ t_4 \end{pmatrix}.\]
Note that $\exists X, Y \in \GL_4(\Z)$ so that $XBY=\diag(\delta_1, \dots, \delta_4)$ with $\delta_1 \mid \cdots \mid \delta_4$. Let $X=(x_{ij})$. Then, we have the following.

\begin{prop}\label{quarticprop} There is a choice of basis $W$ for the module $M$ so that the coordinate sequence $x_1(k)$ of $\alpha(k)$ with respect to the basis $W$ satsfies the initial conditions of Proposition \ref{prop} if and only if 
\[\gcd\left(\chi_4, \frac{\delta_4}{\delta_1}\right)=1,\]
where $\chi_i=x_{i2}+x_{i3}+(\Tr_K(\epsilon)+1)x_{i4}$. 

\begin{proof} Suppose that we have a basis $W=\{w_1, \dots, w_4\}$ for $M$ as above. Set
\[\vec{w}=\begin{pmatrix} w_1 & \cdots & w_4 \end{pmatrix}^{\top} \text{and }\, \vec{t}= \begin{pmatrix} t_1 & \cdots & t_4 \end{pmatrix}^{\top}.\]
Then, $A \vec{w}=B\vec{t}$, where $A$ is a matrix with first column
\[\begin{pmatrix} 0 & a & a & a (\Tr_K(\epsilon)+1) \end{pmatrix}^{\top}.\] 
Write $D=\diag(\delta_1, \dots, \delta_4)$. Then, $D^{-1}XA \vec{w}=Y^{-1}\vec{t}$. Since $Y \in \GL_4(\Z)$, and $\vec{w}$ is a basis for $M$, we must have $C:=D^{-1}XA \in \GL_4(\Z)$. Observe that the first column of $C$ is of the form
\[ \begin{pmatrix} \frac{a}{\delta_1} \chi_1 & \frac{a}{\delta_2} \chi_2 & \frac{a}{\delta_3} \chi_3 & \frac{a}{\delta_4} \chi_4 \end{pmatrix}^{\top}.\]
Since $C \in \GL_4(\Z)$ the entries of this column must be relatively prime. In particular, this implies $a=\delta_4$ and $\gcd(\chi_4, \delta_4/\delta_1)=1$. Conversely, suppose we have $\gcd(\chi_4, \delta_4/\delta_1)=1$. Observe that $\gcd(\chi_1, \dots, \chi_4)=1$, since if there were a prime $p$ dividing every $\chi_i$, then we would have 
\[ p \cdot \begin{pmatrix} q_1 \\ \vdots \\ q_4 \end{pmatrix} = 0 \cdot \begin{pmatrix} x_{11} \\ \vdots \\ x_{41} \end{pmatrix}+
\begin{pmatrix} x_{12} \\ \vdots \\ x_{42} \end{pmatrix}+
 \begin{pmatrix} x_{13} \\ \vdots \\ x_{43} \end{pmatrix}+
(\Tr_K(\epsilon)+1) \begin{pmatrix} x_{14} \\ \vdots \\ x_{44} \end{pmatrix},\]
where $q_i \in \Z$. But then the columns of $X$ would be $(\Z/p)$-linearly dependent, which contradicts the fact that $X \in \GL_4(\Z)$. Now, let 
\[\bar{c}_1 = \begin{pmatrix} \frac{\delta_4}{\delta_1} \chi_1 & \frac{\delta_4}{\delta_2}\chi_2 & \frac{\delta_4}{\delta_3}\chi_3 & \chi_4 \end{pmatrix}^{\top}.\]
A standard result in Geometry of Numbers tells us that a lattice element can be lifted to a basis precisely when it is primitive (see Chapter 1 of \cite{cassels}, for example). Since $\delta_1 \mid \cdots \mid \delta_4$, and we've assumed that $\gcd(\chi_4, \delta_4/\delta_1)=1$, then we have
\[\gcd\left(\frac{\delta_4}{\delta_1} \chi_1, \frac{\delta_4}{\delta_2}\chi_2, \frac{\delta_3}{\delta_2} \chi_3, \chi_4\right)=1.\]
So, there is a matrix $C \in \GL_4(\Z)$ with first column equal to $\vec{c}_1$.
Next, let $A=X^{-1} D C$. Then, $A$ has first column
\[\vec{a}_1=\begin{pmatrix} 0 & \delta_4 & \delta_4 & \delta_4 (\Tr_K(\epsilon)+1) \end{pmatrix}^{\top}.\]
Furthermore, $XD^{-1}A =C \in \GL_4(\Z)$. Let $Z=YD^{-1} X A \in \GL_4(\Z)$, and define a new basis $W=\{w_1, \dots, w_4\}$ from $\{t_1, \dots, t_4\}$ by change of basis matrix $Z^{-1}$. 
Since $Z=B^{-1} A$, we have
\[A \begin{pmatrix} w_1 \\ \vdots \\ w_4 \end{pmatrix} = \begin{pmatrix} \beta \\ \vdots \\ \beta \eta^3 \end{pmatrix}.\]
So, if we write $\alpha(k)=x_1(k)w_1+\cdots+x_4(k)w_4$, then $x_1(k)$ satisfies the initial conditions
$x_1(0)=0, \, x_1(1)=x_1(2)=\delta_4, \, x_1(3)=\delta_4(\Tr_K(\epsilon)+1).$ 
\end{proof}
\end{prop}



Our final Theorem provides a family of modules satisfying the conditions of Proposition \ref{quarticprop}. An interesting future direction could be to provide a characterization of all such modules.

\subsection*{Proof of Theorem \ref{thm2}} Without loss of generality, set $i=1$. Recall that $M=\Z[\sqrt{m}, \sqrt{n}]$ with $m=n+1$, and $\eta=\sqrt{m}+\sqrt{n}$. 
Observe that $\eta=\sqrt{\epsilon}$, where $\epsilon=m+n+2\sqrt{mn}$. Let $K=\Q(\sqrt{m}, \sqrt{n})$ with $m, n$ as above, and $L=\Q(\sqrt{mn})$.  A short computation shows that $N_L(\epsilon)=1$ and $\eta \in \U_M^+$. Next, observe that
\[\begin{pmatrix} 1 \\ \eta \\ \eta^2 \\ \eta^3 \end{pmatrix}=\underbrace{\begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 1 & 0 \\ 2m+1 & 0 & 0 & 2 \\ 0 & 4m+3 & 4m+1 & 0 \end{pmatrix}}_{B} \begin{pmatrix} 1 \\ \sqrt{m} \\ \sqrt{n} \\ \sqrt{mn} \end{pmatrix}.\]
We can compute $XBY=\diag(1, 1, 2, 2)$ where
\[X=\begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & -4m-1 & 0 & 1 \\ -2m-1 & 0 & 1 & 0 \end{pmatrix},
\text{ and }
Y= \begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 1 & -1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix}.
\]
Hence, $\chi_4=1$ and so Proposition \ref{quarticprop} applies. That is, there is a basis $W$ so that the coordinate sequence $x_1(k)$ of $\alpha(k)$ with respect to the basis $W$ satisfies the initial conditions of Proposition \ref{prop}. So, $x_1(k)$ is a LDS.  \hfill \qed 

\begin{rmk} Note that the proof of Proposition \ref{quarticprop} provides an algorithm for computing our desired basis in Theorem \ref{thm2} explicitly. We conclude this paper by demonstrating this computation. Note that \[\Tr_K(\epsilon)=2(m+n)=2m+2,\] where we've used the assumption that $n=m+1$. So, we need to find a matrix $C \in \GL_4(\Z)$ with first column
$\vec{c}_1= \begin{pmatrix} 0 & 2 & 4(1-m) & 1 \end{pmatrix}^{\top}.$
For example, we can take
\[C=\begin{pmatrix} 0 & 0 & 1 & 0 \\ 2 & 0 & 0 & 1 \\ 2(1-m) & 1 & 0 & 0\\ 1 & 0 & 0 & 0 \end{pmatrix}. \]
Then, we compute $A=X^{-1} D C$, where $D=\diag(1, 1, 2, 2)$, to get
\[A=\begin{pmatrix} 0 & 0 & 1 & 0 \\ 2 & 0 & 0 & 1 \\ 2 & 0 & 2m+1 & 0 \\ 2(2m+3) & 2 & 0 & 4m+1 \end{pmatrix}.\]
So, setting $Z=B^{-1} A$, and using $Z^{-1}$ as our change of basis matrix from $\{1, \sqrt{m}, \sqrt{n}, \sqrt{mn}\}$ we obtain basis $W=\{w_1, \dots, w_4\}$ for $M$ given by
\[w_1=\sqrt{mn}, \,\, w_2=\sqrt{m}+2(m-1)\sqrt{mn},\]
\[w_3=1, \,\, w_4=\sqrt{m}+\sqrt{n}-2\sqrt{mn}.\]
So, if we write $\eta^k=x_1(k)w_1+\cdots+x_4(k)w_4$, we can check that $x_1(k)$ satisfies the initial conditions
$x_1(0)=0, \,\, x_1(1)=x_1(2)=2, \,\, x_1(3)=2(2m+3),$
and so by Proposition \ref{prop} we have that $x_1(k)$ is a LDS.
\end{rmk}





\section*{Acknowledgements}

This project was initiated during my visit to the Max Planck Institute for Mathematics, in Bonn, in Spring 2019. I acknowledge the support provided by MPIM in the early stages of this project. This project was also partially supported by the National Science Foundation award DMS-2001281. 




%%%%%%
\bibliography{bib}
\bibliographystyle{plain}



\end{document}