\documentclass[12pt]{amsart}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{etex}
\usepackage[english]{babel}
\usepackage{latexsym}
\usepackage{amsbsy}
\usepackage{amssymb}
\usepackage{amsfonts, amsmath}
\usepackage{mathtools}
\usepackage{csquotes}
\usepackage{pst-tree}
%\usepackage{titlesec}
\usepackage{geometry}
\usepackage{multirow}
\usepackage{blkarray}
\usepackage{tabularx}
\usepackage{arydshln,leftidx,mathtools}
\usepackage{ifthen}
\usepackage{tikz}
\usepackage{tikz-cd}
\usepackage{float}
\usepackage{picins}
\usepackage{amsbsy}
\usetikzlibrary{matrix}
\usetikzlibrary{calc}
\usetikzlibrary{fit}
%\usetikzlibrary{cd}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{mathrsfs,eurosym}
\usepackage{pst-plot,pst-eucl}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}

\usepackage{latexsym}
\usepackage{amsbsy}
\usepackage{alltt}
\usepackage{fontenc}
\usepackage{newlfont}
\usepackage{xlop}
\usepackage{graphicx}% http://ctan.org/pkg/graphicx
\usepackage{yhmath}% http://ctan.org/pkg/yhmath
\usepackage{mathdots}% http://ctan.org/pkg/mathdots

\usepackage{MnSymbol}% http://ctan.org/pkg/mnsymbol
\usepackage{amsthm}
\usepackage{url}
\usepackage{enumerate}

\newtheorem{thrm}{Theorem}[section]
\newtheorem{lem}[thrm]{Lemma}
\newtheorem{prop}[thrm]{Proposition}
\newtheorem{cor}[thrm]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[thrm]{Definition}
\newtheorem{remark}[thrm]{Remark}
\newtheorem{example}[thrm]{Example}
\numberwithin{equation}{section}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{cite}
\DeclareMathOperator{\Span}{span}
\numberwithin{equation}{section}
\newcommand{\rdots}{\hspace{.2ex}\raisebox{1ex}{\rotatebox{-12}{$\ddots$}}}
\newcommand{\e}{{\mathrm{e}}}
\renewcommand\qedsymbol{$\blacksquare$}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS ---------------------------------------------------------------
\title{$\mathcal{P}$-canonical forms and Drazin inverses}
\author{\bf M. MOU\c{C}OUF}
\date{}
\subjclass[2010]{15AXX, 05A10, 11B37, 15A09}

\keywords{Matrix, $\mathcal{P}$-Canonical form, Powers, Linear recurrence sequences, Binomial coefficients, Drazin inverses}
% MATH -------------------------------------------------------------------

%%% ----------------------------------------------------------------------
\begin{document}
\maketitle
\begin{center}
{\footnotesize Department of Mathematics, Faculty of Science, Chouaib Doukkali University,\\Morocco\\
Email: moucouf@hotmail.com}
\end{center}
\begin{abstract}
 We show that the  $\mathcal{P}$-canonical form of $(A^{k})_{k}$ (or simply of the matrix $A$) can be written as a sum of two parts, the geometric and the non-geometric parts of $A$. We also show that if we plug $-k$ for $k$ in the geometric part of $A$, we get the $\mathcal{P}$-canonical form of the Drazin inverse $A_{D}$ of $A$.
\end{abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{sec1}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Let $A$ be a nonsingular matrix over a field $F$. It is a well known fact that, for many numerical examples of matrices $A$, replacing $k$ with $-k$ in certain forms of $A^{k}$, one can obtain The kth power of the inverse $A^{-1}$ of $A$. However, this fact is not proven in general. The problem here is that the kth power of a matrix can be represented in several forms. In fact, It can happen that in certain forms of $A^{k}$ it is not even possible to substitute $k=-1$ and, in other forms we can substitute $k=-1$ but we does not obtain $A^{-1}$. For example, Let $A$ be an $r$-circulant matrix. The expressions of $A^{k}$ given in Theorem 4.1 of~\cite{Mou1} and Theorem 3.1 of~\cite{Mou2} do not provide $A^{-1}$ when we plug into them $k=-1$.
\\In this paper, we consider an arbitrary matrix $A$, singular or nonsingular, and we prove that if we plug $-k$ for $-k$ into the geometric part of $A^{k}$ we get the kth power of the Drazin inverse of $A$. In order to avoid any confusion that may arise by using the plugging-in operation, we begin by showing that the representations of $A^{k}$ into them we plug $-k$ for $k$, are canonical.
\\Throughout this paper, we use the following notations:
\begin{itemize}
\item $F$ denotes a field and $\mathcal{C}_{F}$ denotes the set of all sequences $\pmb{s}=(s_{k})$, $k\geqslant 0$ over $F$. It is well known that $\mathcal{C}_{F}$ is an $F$-algebra under componentwise addition, multiplication and scalar multiplication.
\item $\mathcal{S}^{\ast}=\{\pmb{\lambda}=(\lambda^{k})_{k\geqslant 0}/\lambda\in F, \lambda\neq 0\}$ be the set of all nonzero geometric sequences.
\item $\mathcal{S}^{\circ}=\{\pmb{0}_{i}\in \mathcal{C}_{F}/i\in \mathbb{N}, \pmb{0}_{i}(k)=\delta_{ik}\}$.
\item $\mathcal{S}=\mathcal{S}^{\ast}\cup \mathcal{S}^{\circ}$.
\item $F_{\mathcal{S}}$ denotes the $F$-vector spaces spanned by $\mathcal{S}$. It is well known that $F_{\mathcal{S}}$ is the set of all linear recurrence sequences in $F$ whose carateristic polynomials are of the form $X^{m}P(X)$ where $P(X)$ is square-free and split with nonzero constant terms.
\item $F_{\mathcal{S}^{\ast}}$ denotes the $F$-vector spaces spanned by $\mathcal{S}^{\ast}$. It is well known that $F_{\mathcal{S}^{\ast}}$ is the set of all linear recurrence sequences in $F$ whose carateristic polynomials are square-free and split with nonzero constant terms.
\item $F_{\mathcal{S}^{\circ}}$ denotes the $F$-vector spaces spanned by $\mathcal{S}^{\circ}$. It is well known that $F_{\mathcal{S}^{\circ}}$ the set of all linear recurrence sequences in $F$ whose carateristic polynomials split and have zero as its only root.
\end{itemize}
It is well known from the general theory of linear recurrence sequences that
\begin{itemize}
\item $\mathcal{S}$, $\mathcal{S}^{\ast}$ and $\mathcal{S}^{\circ}$ are basis of $F_{\mathcal{S}}$, $F_{\mathcal{S}^{\ast}}$ and $F_{\mathcal{S}^{\circ}}$, respectively.
\item $F_{\mathcal{S}}$, $F_{\mathcal{S}^{\ast}}$ and $F_{\mathcal{S}^{\circ}}$ are subalgebras of $\mathcal{C}_{F}$. More precisely, the set $\mathcal{S}^{\ast}$ is a group, and hence $F_{\mathcal{S}^{\ast}}$ is exactly the group algebra of $\mathcal{S}^{\ast}$ over $F$.
\item $F_{\mathcal{S}^{\circ}}$ and $F_{\mathcal{S}^{\ast}}$ are supplementary vector spaces relative to $F_{\mathcal{S}}$, i.e., $F_{\mathcal{S}}=F_{\mathcal{S}^{\circ}}\oplus F_{\mathcal{S}^{\ast}}$.
\end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Canonical forms for linear recurrence sequences}
\label{sect:Canonical forms}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Let $\mathcal{T}=\{\Lambda_{i}/i\geqslant 0\}$ be the set of all sequences $\Lambda_{i}=(\binom{k}{i})_{k\geq 0}$ and consider the $F$-vector space $F\langle \mathcal{T} \rangle$ spanned by $\mathcal{T}$. Then we have the following result
\begin{prop}\label{Prop 11}
Let $F$ be a field. Let $\widetilde{\mathcal{T}}$ be the set of all sequences $\widetilde{\Lambda}_{i}=(\binom{-k}{i})_{k\geq 0}$ and consider the sequence $\Gamma=(0,1,2,\ldots)$. Then we have
\\1. $F\langle \mathcal{T} \rangle$ is a subalgebra of $\mathcal{C}_{F}$ and $\mathcal{T}$ is a basis of $F\langle \mathcal{T} \rangle$.
\\2. $\widetilde{\mathcal{T}}$ is a basis of $F\langle \mathcal{T} \rangle$, and the linear automorphism $\chi$ of $F\langle \mathcal{T} \rangle$ which maps $\Lambda_{i}$ to $\widetilde{\Lambda}_{i}$ is an involution of the algebra $F\langle \mathcal{T} \rangle$.
\\3. $F\langle \mathcal{T} \rangle$ and $F_{\mathcal{S}^{\ast}}$ are $F$-linearly disjoint.
\\4. If $F$ is of characteristic $0$, then the sequence $\Gamma$ is transcendental over the ring $F_{\mathcal{S}^{\ast}}$.
\\5. $F_{\mathcal{S}}[\mathcal{T}]=F_{\mathcal{S}^{\circ}}\oplus F_{\mathcal{S}^{\ast}}[\mathcal{T}]$, where $F_{\mathcal{S}}[\mathcal{T}]$ is the subalgebras of $\mathcal{C}_{F}$ obtained by adjoining to $F_{\mathcal{S}}$ the set $\mathcal{T}$.
\end{prop}
\begin{proof}~
\\1. Using the following formula (due to Riordan~\cite{Riord})
\begin{align*}
\binom{k}{i}\binom{k}{j}&=\sum_{m=i}^{i+j} \binom{m}{i}\binom{i}{m-j}\binom{k}{m}\\
&=\sum_{m=0}^{i} \binom{i+j-m}{m,i-m,j-m}\binom{k}{i+j-m}
\end{align*}
we can easily deduce that $\Lambda_{i}\Lambda_{j}$ is a linear combinaison of elements of $\mathcal{T}$ for all $i,j$. Then $F\langle \mathcal{T} \rangle$ is a subalgebra of $\mathcal{C}_{F}$. More precisely, $F\langle \mathcal{T} \rangle$ is the set of all linear recurrence sequences in $F$ with charateristic polynomials split over $F$ and have one as its only root. It is well known that $\mathcal{T}$ is a basis of $F\langle \mathcal{T} \rangle$.
\\2. Let $i\in \mathbb{N}$. It is clear that $\widetilde{\Lambda}_{0}=\Lambda_{0}$ and then $\widetilde{\Lambda}_{0}\in F\langle \mathcal{T} \rangle$. Suppose that $i\geqslant 1$. Then we have $\widetilde{\Lambda}_{i}=(-1)^{i}(\binom{k+i-1}{i})$. An easy application of the Vandermonde convolution shows that
$$\widetilde{\Lambda}_{i}=\sum_{j=1}^{i}(-1)^{i}\binom{i-1}{i-j}\Lambda_{j}.$$
Then $\widetilde{\Lambda}_{i}\in F\langle \mathcal{T} \rangle$ for all $i\in \mathbb{N}$. Since the coordinate matrix of the family $(\widetilde{\Lambda}_{0},\ldots,\widetilde{\Lambda}_{i})$ relative to $(\Lambda_{0},\ldots,\Lambda_{i})$ is the involutory lower triangular Pascal matrix of order $i+1$, it follows that $\widetilde{\mathcal{T}}$ is a basis of $F\langle \mathcal{T} \rangle$ and that $\chi$ is an involution.
\\We note that $\chi$ is an $F$-algebra automorphism is due to the fact that Riordan's formula remains true for any negative integer $k$.
\\3.
Let $\pmb{\lambda}_{1},\ldots,\pmb{\lambda}_{n}$ be any family of pairwise distinct elements of $\mathcal{S}^{\ast}$ and $m$ be a positive integer, and set $P(X)=\displaystyle\prod_{j=1}^{n}(X-\lambda_{j})^{m+1}$. From Theorem 1 and Theorem 2 of~\cite{Fill} assure that $\{\Lambda_{i}\pmb{\lambda}_{j}/1\leqslant j\leqslant n \,\,\text{and}\,\, 0\leqslant i\leqslant m\}$ is a basis of the $F$-vector space of all linear recurrence sequences with characteristic polynomial $P$. It follows that the set $\{\Lambda_{i}\pmb{\lambda}/i\in \mathbb{N}, \pmb{\lambda}\in \mathcal{S}^{\ast}\}$ is linearly independent over the field $F$. The result now follows from Proposition 11.6.1. of~\cite{Cohn} and the fact that $\mathcal{S}^{\ast}$ and $\mathcal{T}$ are bases of the $F$-vector spaces $F_{\mathcal{S}^{\ast}}$ and $F\langle \mathcal{T} \rangle$, respectively.
\\4. It is well known that when $F$ is of characteristic $0$, the family $\{\Gamma^{i}/ i\in \mathbb{N}\}$) plays the same algebraic role as $\mathcal{T}$. By the same argument as in the proof of 3., it turns that the $F$-vector spaces $F_{\mathcal{S}^{\ast}}$ and $F[\Gamma]$ are linearly disjoint. It then follows that $\Gamma$ is transcendental over the ring $F_{\mathcal{S}^{\ast}}$.
\\5. First note that $F_{\mathcal{S}^{\circ}}[\mathcal{T}]=F_{\mathcal{S}^{\circ}}$ since $\pmb{0}_{i}\Lambda_{j}=\binom{i}{j}\pmb{0}_{i}$ for all integers $i$ and $j$. Now, since $$\{\pmb{0}_{0},\ldots,\pmb{0}_{n'}\}\cup\{\Lambda_{i}\pmb{\lambda}_{j}/\pmb{\lambda}_{0},\ldots,\pmb{\lambda}_{n}\in \mathcal{S}^{\ast} \,\,\text{and}\,\, 0\leqslant i\leqslant m\}$$ is linearly independent over the field $F$, because it is a basis of the $F$-vector space of all linear recurrence sequence with characteristic polynomial $X^{n'}\displaystyle\prod_{j=1}^{n}(X-\lambda_{j})^{m+1}$, the result $F_{\mathcal{S}}[\mathcal{T}]=F_{\mathcal{S}^{\circ}}\oplus F_{\mathcal{S}^{\ast}}[\mathcal{T}]$ follows.
\end{proof}
\begin{remark} To be more precise, Proposition 11.6.1. of~\cite{Cohn} shows that if $A$ and $B$ are $F$-subalgebras of $\Omega$ The the following statement are equivalent:
\\1. $A$ and $B$ are $F$-linearly disjoint.
\\2. $\{u_{i}v_{j}\}_{i,j}$ is linearly independent over $F$ whenever $\{u_{i}\}_{i}$ is a $F$-basis of $A$ and $\{v_{j}\}_{j}$ is a $F$-basis of $B$.
\\However, using this result it is easy to prove that the two following statements are also equivalent:
\\1. $A$ and $B$ are $F$-linearly disjoint.
\\2. There exists a $F$-basis $\{u_{i}\}_{i}$ of $A$ and a $F$-basis $\{v_{j}\}_{j}$ of $B$ such that $\{u_{i}v_{j}\}_{i,j}$ is linearly independent over $F$.
\end{remark}
From Proposition~\ref{Prop 11}, it follows that each $\pmb{u}\in F_{\mathcal{S}}[\mathcal{T}]$ can be written in exactly one way as $\pmb{u}=\pmb{v}+\pmb{u}_{0}\Lambda_{0} + \cdots + \pmb{u}_{m}\Lambda_{m}$, in which $\pmb{v}\in F_{\mathcal{S}^{\circ}}$ and $\pmb{u}_{0},\ldots,\pmb{u}_{m}\in F_{\mathcal{S}^{\ast}}$ and that this representation is canonical. For ease of reference, let us call
\begin{itemize}
\item $\pmb{v}+\pmb{u}_{0}\Lambda_{0} + \cdots + \pmb{u}_{m}\Lambda_{m}$ the canonical form of $\pmb{u}$ relative to $(\mathcal{S}^{\ast}, \mathcal{T})$.
\item $\pmb{u}_{0}\Lambda_{0} + \cdots + \pmb{u}_{m}\Lambda_{m}$ the geometric part of $\pmb{u}$ relative to $(\mathcal{S}^{\ast}, \mathcal{T})$.
\item $\pmb{v}$ the non-geometric part of $\pmb{u}$.
\end{itemize}
Before going further let us state the following definition.
\begin{definition} We say a sequence of $F_{\mathcal{S}}[\mathcal{T}]$ to be purely geometric if its non-geometric part is zero.
\end{definition}
\begin{lem}\label{lem 33} Let $\pmb{u}$ a sequence over $F$. Suppose that there exists a sequence $\pmb{w}=\pmb{w}_{0}\Lambda_{0} + \cdots + \pmb{w}_{m}\Lambda_{m}\in F_{\mathcal{S}^{\ast}}[\mathcal{T}]$ and a nonnegative integer $\mathcal{T}$ such that $\pmb{u}_{k}=\pmb{w}_{k}$ for all $k\geq \mathcal{T}$. Then $\pmb{u}\in F_{\mathcal{S}}[\mathcal{T}]$; in this case, $\pmb{w}_{0}\Lambda_{0} + \cdots + \pmb{w}_{m}\Lambda_{m}$ and $(\pmb{u}_{0}-\pmb{w}_{0})\pmb{0}_{0}+\cdots+(\pmb{u}_{\tau-1}-\pmb{w}_{\tau-1})\pmb{0}_{\tau-1}$ are the geometric part and the non-geometric part of $\pmb{u}$, respectively.
\end{lem}
\begin{proof} Follows immediately from the fact that $$\pmb{u}=(\pmb{u}_{0}-\pmb{w}_{0})\pmb{0}_{0}+\cdots+(\pmb{u}_{\tau-1}-\pmb{w}_{\tau-1})\pmb{0}_{\tau-1}+\pmb{w}.$$
\end{proof}
\begin{remark}
It is easily seen that two sequences $\pmb{u}, \pmb{v}\in F_{\mathcal{S}}[\mathcal{T}]$ are shift equivalent if and only if they have the same geometric parts.
\end{remark}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{$\mathcal{P}$-canonical forms of matrices}
\label{sect:canonical forms of matrices}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Let $\mathbf{M_{q}}(\mathcal{C}_{F})$ be the set of all matrices of order $q$ over $\mathcal{C}_{F}$ and let $$\mathbf{M_{q}}(F_{\mathcal{S}})_{\mathcal{T}}=\mathbf{M_{q}}(F_{\mathcal{S}})\langle\mathcal{T}\rangle$$ be the subalgebra of $\mathbf{M_{q}}(\mathcal{C}_{F})$ obtained by adjoining to $\mathbf{M_{q}}(F_{\mathcal{S}})$ the set $\mathcal{T}$. It is straightforward to check that $\mathbf{M_{q}}(F_{\mathcal{S}})_{\mathcal{T}}$ is the set of all sequence matrices of order $q$ over $\mathcal{C}_{F}$ that are linear recurrence sequences with characteristic polynomials split over $F$, and that $\mathbf{M_{q}}(F_{\mathcal{S}^{\circ}})$ is the subset of all $\mathbf{M_{q}}(F_{\mathcal{S}})_{\mathcal{T}}$ consisting of all sequence matrices whose terms vanish from some point onwards. Since $$\mathbf{M_{q}}(F_{\mathcal{S}})_{\mathcal{T}}=
\mathbf{M_{q}}(F_{\mathcal{S}^{\circ}})\oplus\mathbf{M_{q}}(F_{\mathcal{S}^{\ast}})_{\mathcal{T}},$$ it follows that each $\pmb{U}\in \mathbf{M_{q}}(F_{\mathcal{S}})_{\mathcal{T}}$ can be written in exactly one way as $\pmb{U}=\pmb{V}+\pmb{W}$, in which $\pmb{V}\in \mathbf{M_{q}}(F_{\mathcal{S}^{\circ}})$ and $\pmb{W}\in \mathbf{M_{q}}(F_{\mathcal{S}^{\ast}})_{\mathcal{T}}$. Let $\pmb{U_{ij}}$ be the $(i, j)$-th entrie of $\pmb{U}$, then $\pmb{V_{ij}}$ and $\pmb{W_{ij}}$ are the non-geometric part and the geometric part of $\pmb{U_{ij}}$, respectively. We say then that $\pmb{V}$ and $\pmb{W}$ are the non-geometric part and the geometric part of $\pmb{U}$, respectively. We note that there exist matrices $\mathcal{V}_{0},\ldots, \mathcal{V}_{n}$ with coefficients in $F$ and $\mathcal{W}_{0},\ldots, \mathcal{W}_{m}$ with coefficients in $F_{\mathcal{S}^{\ast}}$ such that
$$\pmb{V}=\mathcal{V}_{0}\pmb{0}_{0}+\cdots+\mathcal{V}_{n}\pmb{0}_{n}\quad\text{is the non-geometric part of}\quad \pmb{U}$$
and
$$\pmb{W}=\mathcal{W}_{0}\Lambda_{0}+\cdots+\mathcal{W}_{m}\Lambda_{m}\quad\text{is the geometric part of}\quad \pmb{U}.$$
We note that, in view of Proposition~\ref{Prop 11}, the matrices $\mathcal{V}_{0},\ldots, \mathcal{V}_{n}$ and $\mathcal{W}_{0},\ldots, \mathcal{W}_{m}$ are uniquely determined by $\pmb{U}$. We conclude that every matrix $\pmb{U}$ of $\mathbf{M_{q}}(F_{\mathcal{S}})_{\mathcal{T}}$ can be written in the form $$\pmb{U}=\mathcal{V}_{0}\pmb{0}_{0}+\cdots+\mathcal{V}_{n}\pmb{0}_{n}+\mathcal{W}_{0}\Lambda_{0}+
\cdots+\mathcal{W}_{m}\Lambda_{m},$$ where $\mathcal{V}_{0},\ldots, \mathcal{V}_{n}\in \mathbf{M_{q}}(F)$ and $\mathcal{W}_{0},\ldots, \mathcal{W}_{m}\in \mathbf{M_{q}}(F_{\mathcal{S}^{\ast}})$, and that these matrices are uniquely determined by $\pmb{U}$. Let us call this representation the $\mathcal{P}$-canonical form of $\pmb{U}$, and let us abbreviate this with \enquote{$\mathcal{P}$-cf}.
\\Let now $A$ be a matrix over $F$ and let $P_{A}$ be its characteristic polynomial. It is well known that the entries of $\pmb{A}=(A^{k})_{k\geq 0}$ are linear recurrence sequences with characteristic polynomial $P_{A}$. From this it follows that if $P_{A}$ splits over $F$, then $$\pmb{A}\in \mathbf{M_{q}}(F_{\mathcal{S}})_{\mathcal{T}}=
\mathbf{M_{q}}(F_{\mathcal{S}^{\circ}})\oplus\mathbf{M_{q}}(F_{\mathcal{S}^{\ast}})_{\mathcal{T}},$$ and hence from the discussion above , there exist matrices $\mathcal{A}_{0},\ldots, \mathcal{A}_{m}$ with coefficients in $F_{\mathcal{S}^{\ast}}$ and a matrix $N(A)$ with coefficients in $F_{\mathcal{S}^{\circ}}$ such that
 $$\pmb{A}= N(A) + \mathcal{A}_{0}\Lambda_{0} + \cdots + \mathcal{A}_{m}\Lambda_{m},$$
and this representation is the \enquote{$\mathcal{P}$-cf} of $\pmb{A}$, or simply of $A$.
In the following proposition we give some properties of the matrices $N(A),\mathcal{A}_{0},\ldots, \mathcal{A}_{m}$.
\begin{prop}\label{Prop 23} Let $A$ be a square matrix of order $q$ over $F$, and suppose that its minimal polynomial is of the form $m_{A}=X^{t_{0}}\prod_{j=1}^{p}\displaystyle(X-\lambda_{j})^{t_{j}}$ with the $\lambda_{j}$ distinct and belong to $F$(possibly $t_{0}=0$). Let $\pi_{0},\ldots,\pi_{p}$ be the spectral projections of $A$ at $0,\lambda_{1},\ldots,\lambda_{p}$, respectively. Then we have
\\1. $\mathcal{A}_{i}=\displaystyle\sum_{j=1}^{p}\pmb{\lambda}_{j}\lambda_{j}^{-i}(A-\lambda_{j}I_{q})^{i}\pi_{j}$, $i\geqslant 1$, $\mathcal{A}_{0}=\pmb{\lambda}_{1}\pi_{1}+\cdots+\pmb{\lambda}_{p}\pi_{p}$.
\\2. $N(A)=\displaystyle\sum_{i=0}^{t_{0}-1}\pmb{0}_{i}A^{i}\pi_{0}$ ($N(A)=0$ if and only if $t_{0}=0$).
\\3. $A$ is nilpotent if and only if each $\mathcal{A}_{i}$ is zero, i.e., $\pmb{A}= N(A)$.
\\4. $\mathcal{A}_{i}=0$ if and only if $i> m=\max\{t_{1}-1,\ldots,t_{p}-1\}$.
\\5. If $A$ is not nilpotent, then no coefficient $\mathcal{A}_{i}$, $1\leq i\leq m$, is zero.
\\6. $\mathcal{A}_{i}=\displaystyle\sum_{j=1}^{p}\pmb{\lambda}_{j}\lambda_{j}^{-i}(A-\lambda_{j}I_{q})^{i}\pi_{j}$ is a nilpotent matrix, $i\geqslant 1$.
\\7. $N(A)=\pmb{0}_{0}\pi_{0}+N$ where $N$ is a nilpotent matrix.
\\8. $\pmb{A}= (N + \mathcal{A}_{1}\Lambda_{1} + \cdots + \mathcal{A}_{m}\Lambda_{m}) + (\pmb{0}_{0}\pi_{0}+\mathcal{A}_{0}\Lambda_{0})$ is the unique decomposition of $\pmb{A}$ as a sum of commuting nilpotent and diagonalizable matrices.
\end{prop}
\begin{proof}~
\\1. and 2. We know that $$I_{q}=\pi_{0}+\pi_{1}+\cdots+\pi_{p},$$ then $$A=(A\pi_{0})\pi_{0}+(A\pi_{1})\pi_{1}+\cdots+(A\pi_{p})\pi_{p}$$ and hence $$A^{k}=(A\pi_{0})^{k}\pi_{0}+(A\pi_{1})^{k}\pi_{1}+\cdots+(A\pi_{p})^{k}\pi_{p}$$ for all $k\geqslant 0$. But since $A\pi_{i}=(A-\lambda_{i}I_{q})\pi_{i}+\lambda_{i}\pi_{i}$ and $(A-\lambda_{i}I_{q})^{t_{i}}\pi_{i}=0$, we see that $$A^{k}=\sum_{i=0}^{t_{0}-1}0^{k-i}\binom{k}{i}A^{i}\pi_{0}+\sum_{i=1}^{p}(\sum_{j=0}^{s}\lambda_{i}^{k-j}(A-\lambda_{i}I_{q})^{j}\pi_{i}\binom{k}{j})$$
for all $k\geqslant 0$ and $s\geqslant \max\{t_{1}-1,\ldots,t_{p}-1\}$.
Therefore, $$\pmb{A}= N(A) + \mathcal{A}_{0}\Lambda_{0} + \cdots + \mathcal{A}_{s}\Lambda_{s},$$ where $$\mathcal{A}_{i}=\displaystyle\sum_{j=1}^{p}\pmb{\lambda}_{j}\lambda_{j}^{-i}(A-\lambda_{j}I_{q})^{i}\pi_{j}, 1\leqslant i\leqslant s,$$
$$\mathcal{A}_{0}=\pmb{\lambda}_{1}\pi_{1}+\cdots+\pmb{\lambda}_{p}\pi_{p}$$ and $$N(A)=\displaystyle\sum_{i=0}^{t_{0}-1}\pmb{0}_{i}A^{i}\pi_{0}.$$
3. Is evident.
\\4. Let $E^{1},\ldots,E^{p}$ be the generalized eigenspaces corresponding to $\lambda_{1},\ldots,\lambda_{p}$, respectively. Let $v\in E^{s}$ and suppose $\mathcal{A}_{i}=0$. Then we have $\displaystyle\sum_{j=1}^{p}\pmb{\lambda}_{j}\lambda_{j}^{-i}(A-\lambda_{j}I_{q})^{i}\pi_{j}(v)=0$, hence $\pmb{\lambda}_{s}\lambda_{s}^{-i}(A-\lambda_{s}I_{q})^{i}(v)=0$. So $(A-\lambda_{s}I_{q})^{i}(v)=0$. Therefore, $E^{s}\subseteq ker(A-\lambda_{s}I_{q})^{i}$ and then $i\geqslant t_{s}$. Consequently, we have $i> m=\max\{t_{1}-1,\ldots,t_{p}-1\}$.
\\The converse follows immediately from the fact that $$A^{t_{0}}\pi_{0}=(A-\lambda_{j}I_{q})^{t_{j}}\pi_{j}=0, 1\leqslant j\leqslant p.$$
\\5. Is evident.
\\6. Follows from the fact that if $i\geqslant 1$ then $\mathcal{A}_{i}$ is a sum of commuting nilpotent matrices.
\\7. Is evident.
\\8. Let $A=A_{n}+A_{s}$ be the Jordan-Chevalley decomposition of $A$. Then $A^{k}=(A_{n}+A_{s})^{k}=B_{k}+A^{k}_{s}$ where $B_{k}$ is a matrix which commutes with $A_{n}$ and $A_{s}$. More precisely, $A^{k}=B_{k}+A^{k}_{s}$ is the Jordan-Chevalley decomposition of $A^{k}$. Since $(A^{k}_{s})=\pmb{0}_{0}\pi_{0}+\mathcal{A}_{0}\Lambda_{0}$ it follows that $(B_{k})=N + \mathcal{A}_{1}\Lambda_{1} + \cdots + \mathcal{A}_{m}\Lambda_{m}$. The fact that the matrices $A_{s}^{k}, k\geqslant 0$ are simultaneously diagonalizable guarantees that the sequence matrix $(A_{s}^{k})$ is diagonalizable.
\end{proof}
\begin{remark}
The elements $\pmb{0}_{0},\pmb{\lambda}_{1},\ldots,\pmb{\lambda}_{p}$ are the only geometric sequences that are eigenvalues of the sequence matrix $\pmb{A}$.
\end{remark}
\begin{remark}
$A$ is invertible if and only if $N(A)=0$.
\end{remark}
\begin{remark}
If we plug $k=0$ into $(\mathcal{A}_{0}\Lambda_{0} + \cdots + \mathcal{A}_{m}\Lambda_{m})_{k}$, we get $\pi_{1}+\cdots+\pi_{p}=I_{q}-\pi_{0}$. Thus, if we have already determined the geometric part of a matrix $A$, then we can easily check whether or not $A$ is nonsingular. For this, it is sufficient to plug $k=0$ into the geometric part of $A$ and see if we get the identity matrix or not.
\end{remark}
We have the following corollaries
\begin{cor}\label{Cor 21} Let $A$ be a square matrix over $F$ and let $t_{0}$ be its index. Suppose there exists a purely geometric sequence $A(k)_{k\geq 0}$ and a nonnegative integer $\tau$ such that $A^{k}=A(k)$ for all $k\geq \tau$. Then we have
\\1. $t_{0}\leq \tau$.
\\2. $t_{0}$ is the smallest nonnegative integer for which $A^{t_{0}}=A(t_{0})$.
\end{cor}
\proof
On the one hand, according to Lemma~\ref{lem 33}, $$N(A)=(I-A(0))\pmb{0}_{0}+(A-A(1))\pmb{0}_{1}+\cdots+(A^{\tau-1}-A(\tau-1))\pmb{0}_{\tau-1}.$$
On the other hand, according to Proposition~\ref{Prop 23},
$$N(A)=\displaystyle\sum_{i=0}^{t_{0}-1}\pmb{0}_{i}A^{i}\pi_{0}.$$
Therefore, it follows that $t_{0}\leq \tau$ Since $t_{0}$ is the smallest nonnegative integer for which $A^{t_{0}}\pi_{0}=0$. Furthermore, the unicity of the representation of $N(A)$ ensures that $A^{i}-A(i)=A^{i}\pi_{0}\neq 0$, $0\leq i\leq t_{0}-1$ and $A^{i}-A(i)=0$, $t_{0}\leq i\leq \tau$. Therefore,  $t_{0}$ is the smallest nonnegative integer for which $A^{t_{0}}=A(t_{0})$. This completes the proof of the corollary.
\endproof
\begin{cor}\label{Cor 22} Let $A$ be a square matrix over $F$. Then the minimal polynomial of $A$ is $m_{A}(X)=X^{t_{0}}\prod_{j=1}^{p}(X-\lambda_{j})^{t_{j}}$, where $t_{0}$ and $t_{j}, j\neq 0$, are respectively the greatest integers such that $\pmb{0}_{t_{0}-1}$ and $\pmb{\lambda}_{j}\Lambda_{t_{j}-1}$ appear in the $\mathcal{P}$-cf of $A$.
\end{cor}
\proof
The proof of the Corollary follows immediately from the fact that $t_{0}$ and $t_{j}$, $1\leq j \leq p$ are the the smallest nonnegative integer for which $A^{t_{0}}\pi_{0}=0$ and $(A-\lambda_{j}I_{q})^{t_{j}}\pi_{j}=0$.
\endproof
\begin{cor}\label{Cor 23} Let $A$ be a square matrix over $F$ such that its characteristic polynomial splits over $F$. Then $A$ is diagonalizable if and only if the geometric part of $A$ is an element of $\mathbf{M_{q}}(F_{\mathcal{S}^{\ast}})$ and the non-geometric part of $A$ is an element of $\pmb{0}_{0}\mathbf{M_{q}}(F)$.
\end{cor}
\proof A direct consequence of Proposition~\ref{Prop 23}.
\endproof
The following example is from~\cite{Male}.
\begin{example}\label{example 1}
Let $$A=\begin{pmatrix}
1&1&1&0\\1&1&1&-1\\0&0&-1&1\\0&0&1&-1
\end{pmatrix}$$
and let $A(k)$ be the sequence matrix
$$A(k)=\begin{pmatrix}
2^{-1+k}&2^{-1+k}&\frac{1}{16}2^{k}((-1)^{1+k}+5)&\frac{1}{16}2^{k}((-1)^{k}-1)\vspace*{0.1pc}\\
2^{-1+k}&2^{-1+k}&\frac{5}{16}2^{k}((-1)^{1+k}+1)&\frac{1}{16}2^{k}(5(-1)^{k}-1)\vspace*{0.1pc}\\
0&0&(-1)^{k}2^{-1+k}&(-1)^{1+k}2^{-1+k}\vspace*{0.1pc}\\
0&0&(-1)^{1+k}2^{-1+k}&(-1)^{k}2^{-1+k}
\end{pmatrix}.$$
We can verify that $A^{k}=A(k)$ for all $k\geq 4$. We have $A(0)\neq I_{4}$, then $A$ is singular.
\\$A(1)\neq A$, $A(2)=A^{2}$, $A(3)=A^{3}$.
\\Then we have
\begin{itemize}
\item The non-geometric part of $A$ is $(I_{4}-A(0))\pmb{0}_{0}+(A-A(1))\pmb{0}_{1}$.
\item The geometric part of $A$ is
$$\begin{pmatrix}
2^{-1}(2^{k})&2^{-1}(2^{k})&\frac{5}{16}(2^{k})-\frac{1}{16}((-2)^{k})&\frac{-1}{16}(2^{k})+\frac{1}{16}((-2)^{k})\vspace*{0.1pc}\\
2^{-1}(2^{k})&2^{-1}(2^{k})&\frac{5}{16}(2^{k})-\frac{5}{16}((-2)^{k})&\frac{-1}{16}(2^{k})+\frac{5}{16}((-2)^{k})\vspace*{0.1pc}\\
0&0&2^{-1}((-2)^{k})&-2^{-1}((-2)^{k})\vspace*{0.1pc}\\
0&0&-2^{-1}((-2)^{k})&2^{-1}((-2)^{k})
\end{pmatrix}$$
\item The minimal polynomial of $A$ is $X^{2}(X-2)(X+2)$.
\item $\pi_{0}=I_{4}-A(0)=$,
$\pi_{2}=\begin{pmatrix}
2^{-1}&2^{-1}&\frac{5}{16}&\frac{-1}{16}\vspace*{0.1pc}\\
2^{-1}&2^{-1}&\frac{5}{16}&\frac{-1}{16}\vspace*{0.1pc}\\
0&0&0&0\vspace*{0.1pc}\\
0&0&0&0
\end{pmatrix}$ and $\pi_{-2}=\begin{pmatrix}
0&0&\frac{-1}{16}&\frac{1}{16}\vspace*{0.1pc}\\
0&0&\frac{-5}{16}&\frac{5}{16}\vspace*{0.1pc}\\
0&0&2^{-1}&-2^{-1}\vspace*{0.1pc}\\
0&0&-2^{-1}&2^{-1}
\end{pmatrix}$
\end{itemize}
\end{example}
Consider now the unique linear map
\begin{align*}
\theta: F_{\mathcal{S}^{\ast}} &\longrightarrow F_{\mathcal{S}^{\ast}}\\
\pmb{\lambda} &\longmapsto \pmb{\lambda}^{-1}
\end{align*}
Obviously, $\theta(\mathcal{S}^{\ast})=\mathcal{S}^{\ast}$ and $\theta^{-1}=\theta$. Since $\theta(\pmb{\lambda}\pmb{\mu})=\theta(\pmb{\lambda})\theta(\pmb{\mu})$ for all $\pmb{\lambda}, \pmb{\mu}\in \mathcal{S}^{\ast}$, it follows that $\theta$ is an $F$-algebra automorphism of $F_{\mathcal{S}^{\ast}}$.
\\Let \begin{align*}
\Psi: F_{\mathcal{S}^{\circ}} \longrightarrow F_{\mathcal{S}^{\circ}}
\end{align*}
be any $F$-endomorphism of $F_{\mathcal{S}^{\circ}}$ and consider
\begin{align*}
\Psi\oplus \theta: F_{\mathcal{S}} \longrightarrow F_{\mathcal{S}}
\end{align*}
The direct sum of $\theta$ and $\Psi$. It is obvious that $\theta_{\Psi}$ is an $F$-endomorphism of $F_{\mathcal{S}}$, involutory if $\Psi$ is, but it is not an algebra homomorphism; in fact, we have $\pmb{\lambda}\pmb{0}_{i}=\lambda^{i}\pmb{0}_{i}$, then $\theta_{\Psi}(\pmb{\lambda}\pmb{0}_{i})=\lambda^{i}\Psi(\pmb{0}_{i})$ which is not always equal to $\theta_{\Psi}(\pmb{\lambda})\theta_{\Psi}(\pmb{0}_{i})=\pmb{\lambda}^{-1}\Psi(\pmb{0}_{i})$.
\\Let us denote by $\widetilde{\theta}$ the $F$-algebra automorphism
\begin{align*}
\widetilde{\theta}: \mathbf{M_{q}}(F_{\mathcal{S}^{\ast}}) &\longrightarrow \mathbf{M_{q}}(F_{\mathcal{S}^{\ast}})\\
(A_{ij}) &\longmapsto (\theta(A_{ij}))
\end{align*}
Note that $\widetilde{\theta}$ is an involution of $\mathbf{M_{q}}(F_{\mathcal{S}^{\ast}})$.
\\Let $\widetilde{\theta}_{\Psi}$ denotes the linear endomorphism induced by $\theta_{\Psi}$ on $\mathbf{M_{q}}(F_{\mathcal{S}})_{\mathcal{T}}=
\mathbf{M_{q}}(F_{\mathcal{S}^{\circ}})\oplus\mathbf{M_{q}}(F_{\mathcal{S}^{\ast}})_{\mathcal{T}}$ defined by
\begin{align*}
\widetilde{\theta}_{\Psi}: \mathbf{M_{q}}(F_{\mathcal{S}})_{\mathcal{T}} &\longrightarrow \mathbf{M_{q}}(F_{\mathcal{S}})_{\mathcal{T}}\\
\pmb{U} &\longmapsto \mathcal{V}_{0}\Psi(\pmb{0}_{0})+\cdots+\mathcal{V}_{n}\Psi(\pmb{0}_{n})+
\widetilde{\theta}(\mathcal{W}_{0})\widetilde{\Lambda_{0}}+\cdots+\widetilde{\theta}(\mathcal{W}_{m})\widetilde{\Lambda_{m}},
\end{align*}
where $$\mathcal{V}_{0}\pmb{0}_{0}+\cdots+\mathcal{V}_{n}\pmb{0}_{n}+\mathcal{W}_{0}\Lambda_{0}+\cdots+\mathcal{W}_{m}\Lambda_{m}$$
is the $\mathcal{P}$-cf of $\pmb{U}$. The map $\widetilde{\theta}_{\Psi}$ is well-defined, since $\widetilde{\Lambda_{i}}\in F\langle\mathcal{T}\rangle$ for all non-negative integer $i$ (see Proposition~\ref{Prop 11}).
\\In the remainder of this section, we will only be interested in the special case when $\Psi$ is the zero map. Let us denote  the map $$0\oplus \theta: F_{\mathcal{S}} \longrightarrow F_{\mathcal{S}}$$
simply by $\theta_{0}$. It should be noted that the image of a sequence $\pmb{u}$ of $F_{\mathcal{S}}$ under $\theta_{0}$ can be obtained by simply plugging in $-k$ for $k$ in the geometric part of $\pmb{u}$ and neglecting its non-geometric part.
\\Let $A$ be a square matrix of index $t_{0}$ with characteristic polynomial splits over $F$. We may assume that the Jordan canonical form of $A$ has the form as follows
$$A=P\begin{pmatrix} D&0\\ 0&N \end{pmatrix}P^{-1}$$
where $P$ is a nonsingular matrix, $D$ is a nonsingular matrix of order $r=\text{rank}(A^{t_{0}})$, and $N$ is a
nilpotent matrix such that $N^{t_{0}}=0$. Then we can write the matrix $\pmb{A}$ in the form
$$\pmb{A}=P\begin{pmatrix} 0&0\\ 0&N^{k} \end{pmatrix}_{\hspace*{-0.2pc} k}P^{-1} + P\begin{pmatrix} D^{k}&0\\ 0&0 \end{pmatrix}_{\hspace*{-0.2pc} k}P^{-1}.$$
It is clear that these two matrices are the non-geometric and the geometric parts of $\pmb{A}$ written in a form other than the $\mathcal{P}$-cf. If we plug $-k$ for $k$ into this form of the geometric part of $\pmb{A}$, we get the matrix $\pmb{A}_{d}-\pi_{0}\pmb{0}_{0}$. In the theorem below, we show that the same remains true for the $\mathcal{P}$-cf of $\pmb{A}$.
\begin{thrm}\label{thm 535}
Let $A$ be a square matrix of index $t_{0}$ with coefficients in $F$ such that its characteristic polynomial splits over $F$. Then we have $\pmb{A}_{d}=\widetilde{\theta}_{0}(\pmb{A})+\pmb{0}_{0}\pi_{0}$, where $\pmb{A}_{d}=(A_{d}^{k})_{k}$.
\end{thrm}
\begin{proof} We must proof that
$$\begin{array}{rrlc}
\pmb{A}^{t_{0}+1}(\widetilde{\theta}_{0}(\pmb{A})+\pmb{0}_{0}\pi_{0})&=&\pmb{A}^{t_{0}}\quad\quad &(1^{t_{0}})\\
(\widetilde{\theta}_{0}(\pmb{A})+\pmb{0}_{0}\pi_{0})\pmb{A}(\widetilde{\theta}_{0}(\pmb{A})+
\pmb{0}_{0}\pi_{0})&=&\widetilde{\theta}_{0}(\pmb{A})+\pmb{0}_{0}\pi_{0} \quad\quad &(3)\\
\pmb{A}(\widetilde{\theta}_{0}(\pmb{A})+\pmb{0}_{0}\pi_{0})&=&(\widetilde{\theta}_{0}(\pmb{A})+\pmb{0}_{0}\pi_{0})\pmb{A} \quad\quad &(5)
\end{array}$$
From Proposition~\ref{Prop 23} it follows that
$$\pmb{A}=\displaystyle\sum_{i=0}^{t_{0}-1}\pmb{0}_{i}A^{i}\pi_{0} + \sum_{i=0}^{m}(\sum_{j=1}^{p}\pmb{\lambda}_{j}\lambda_{j}^{-i}(A-\lambda_{j}I_{q})^{i}\pi_{j})\Lambda_{i}$$ and then $$\widetilde{\theta}_{0}(\pmb{A})=
\displaystyle\sum_{i=0}^{m}(\sum_{j=1}^{p}\pmb{\lambda}^{-1}_{j}\lambda_{j}^{-i}(A-\lambda_{j}I_{q})^{i}\pi_{j})
\widetilde{\Lambda}_{i},$$ where $m=\max\{t_{1}-1,\ldots,t_{p}-1\}$.
\\Clearly that $\widetilde{\theta}_{0}(\pmb{A})+\pmb{0}_{0}\pi_{0}$ satisfies $(5)$.
\\In order to prove that $\widetilde{\theta}_{0}(\pmb{A})+\pmb{0}_{0}\pi_{0}$ satisfies $(3)$, observe first that $$\mathcal{A}_{i}\Lambda_{i}\widetilde{\theta}_{0}(\mathcal{A}_{l}\Lambda_{l})=
\displaystyle\sum_{j=1}^{p}\lambda_{j}^{-(i+l)}(A-\lambda_{j}I_{q})^{i+l}\pi_{j}\Lambda_{i}\widetilde{\Lambda}_{l}.$$
As $(A-\lambda_{j}I_{q})^{m+1}\pi_{j}=0$, it follows that $$\pmb{A}\widetilde{\theta}_{0}(\pmb{A})=
\displaystyle\sum_{j=1}^{p}\sum_{i=0}^{m}\lambda_{j}^{-i}(A-\lambda_{j}I_{q})^{i}\pi_{j})
(\sum_{l=0}^{i}\Lambda_{l}\widetilde{\Lambda}_{i-l}).$$
Furthermore, since $\displaystyle\sum_{l=0}^{i}\binom{k}{l}\binom{-k}{i-l}=0$ for all positive integer $i$, we also have $$\displaystyle\sum_{l=0}^{i}\Lambda_{l}\widetilde{\Lambda}_{i-l}=\pmb{0}.$$
Therefore, $$\pmb{A}\widetilde{\theta}_{0}(\pmb{A})=\displaystyle\sum_{j=1}^{p}\pi_{j}=
I_{q}-\pi_{0}.$$ Hence $$\widetilde{\theta}_{0}(\pmb{A})\pmb{A}\widetilde{\theta}_{0}(\pmb{A})=\widetilde{\theta}_{0}(\pmb{A})-
\pi_{0}\widetilde{\theta}_{0}(\pmb{A})=
\widetilde{\theta}_{0}(\pmb{A})$$ and because of $\pmb{A}\pmb{0}_{0}^{2}\pi_{0}^{2}=\pmb{0}_{0}\pi_{0}$, we conclude that
$$(\widetilde{\theta}_{0}(\pmb{A})+\pmb{0}_{0}\pi_{0})\pmb{A}(\widetilde{\theta}_{0}(\pmb{A})+
\pmb{0}_{0}\pi_{0})=\widetilde{\theta}_{0}(\pmb{A})+\pmb{0}_{0}\pi_{0}.$$
To complete the proof, it remains to show that $\widetilde{\theta}_{0}(\pmb{A})+\pmb{0}_{0}\pi_{0}$ satisfies $(1^{t_{0}})$. Since $\pmb{A}\widetilde{\theta}_{0}(\pmb{A})=I_{q}-\pi_{0}$ and $\pmb{A}^{t_{0}}\pi_{0}=\pmb{0}_{0}\pi_{0}$, it follows that $$\pmb{A}^{t_{0}+1}\widetilde{\theta}_{0}(\pmb{A})=\pmb{A}^{t_{0}}-\pmb{A}^{t_{0}}\pi_{0}=\pmb{A}^{t_{0}}-\pmb{0}_{0}\pi_{0}.$$ But since $\pmb{A}^{t_{0}+1}\pmb{0}_{0}\pi_{0}=\pmb{0}_{0}\pi_{0}$, it follows that $$\pmb{A}^{t_{0}+1}(\widetilde{\theta}_{0}(\pmb{A})+\pmb{0}_{0}\pi_{0})=\pmb{A}^{t_{0}}.$$
The uniqueness of a $\{1^{t_{0}},3,5\}$-inverse $(B_{k})_{k}$ of $\pmb{A}$ follows from the uniqueness of each $B_{k}$ which is the unique $\{1^{t_{0}},3,5\}$-inverse of $A^{k}$, for all positive integer $k$. We conclude that $\widetilde{\theta}_{0}(\pmb{A})+\pmb{0}_{0}\pi_{0}$ is the $\{1^{t_{0}},3,5\}$-inverse of $\pmb{A}$.
\end{proof}
\begin{remark}~
\\1. Although we have specified that the set $F$ is a field and that the characteristic polynomial of $A$ splits over $F$, the theorem~\ref{thm 535} remains true in any integral domain $R$ and for any square matrix. In this case, $A_{d}$ is a matrix over the algebraic closure of the quotient field of $R$.
\\2. If $F=\mathbb{C}$ is the complex field, then $A_{d}=(\pmb{A}_{d})_{1}=\widetilde{\theta}_{0}(\pmb{A})_{1}=
\displaystyle\sum_{j=1}^{p} \pi_{j} \sum_{i=0}^{m}\lambda_{j}^{-i-1}(A-\lambda_{j}I_{q})^{i})(\widetilde{\Lambda}_{i})_{1}=\sum_{j=1}^{p} \pi_{j} \sum_{i=0}^{m}(-1)^{i}\lambda_{j}^{-i-1}(A-\lambda_{j}I_{q})^{i})$. We find then the well-known result that $A_{d}=\frac{1}{z}(A)$ is the matrix function corresponding to the reciprocal $f(z)= \frac{1}{z}$, defined on nonzero eigenvalues (see e.g. Corollary 1. p. 165 of~\cite{Ben}).
\end{remark}
Let now $\mathcal{H}$ be a basis of the free $F_{\mathcal{S}^{\ast}}$-module $F_{\mathcal{S}^{\ast}}\langle \mathcal{T} \rangle$. Since $\mathcal{H}$ has the same cardinality as $\mathcal{T}$, it can be indexed by $\mathbb{N}$, i.e., $\mathcal{H}=\{H_{i}\}_{i\in \mathbb{N}}$.
\begin{prop}\label{Prop : 010}  Let Let $F$ be a field of characteristic $0$ and $\mathcal{H}=\{H_{i}\}_{i\in \mathbb{N}}$ be a basis of the $F_{\mathcal{S}^{\ast}}$-module $F_{\mathcal{S}^{\ast}}\langle \mathcal{T} \rangle$. Assume that $\mathcal{H}$ is contained in the $F$-vector space spanned by $\mathcal{T}$. Then we have the following:
\\1. For all nonnegative integer $i$, there exists a polynomial $P_{i}(X)\in F[X]$ such that $H_{i}=(P_{i}(k))_{k\geq0}$.
\\2. $\widetilde{\theta}(H_{i})=(P_{i}(-k))_{k\geq0}$ For all nonnegative integer $i$.
\\3. Let $A$ be a square matrix over $F$ whose characteristic polynomial splits over $F$. Let $$\pmb{A}= N(A) + \mathcal{B}_{0}(P_{0}(k))_{k} + \cdots + \mathcal{B}_{m}(P_{m}(k))_{k}$$ be the representation of $A$ with respect to $(\mathcal{S}^{\ast}, \mathcal{H})$, which we call the $\mathcal{P}$-cf of $A$ relative to $(\mathcal{S}^{\ast}, \mathcal{H})$. Then the sequence matrix obtained by plugging $-k$ for $k$ in the geometric part $$\mathcal{B}_{0}(P_{0}(k))_{k} + \cdots + \mathcal{B}_{m}(P_{m}(k))_{k}$$ of $A$ is $\pmb{A}_{d}-\pi_{0}\pmb{0}_{0}$.
\end{prop}
\proof~
\\1. It is well known that when the characteristic of $F$ is $0$, $\binom{k}{j}$ is a polynomial in $k$, i.e., there exists $Q_{j}(X)\in F[X]$ such that $\binom{k}{j}=Q_{j}(k)$ and then $\Lambda_{j}=(Q_{j}(k))_{k\geq 0}$. Since $\mathcal{H}$ is contained in the $F$-vector space spanned by $\mathcal{T}$, there exist elements $aij$ in $F$, such that
$$H_{i}=\sum_{finite} a_{ij}\Lambda_{j}.$$
In other words, $H_{i}=(P_{i}(k))_{k\geq0}$, where
$$P_{i}(k)=\sum_{finite} a_{ij}Q_{j}(k).$$
2. It is well known that the equality $\binom{k}{j}=Q_{j}(k)$, which is between two different forms of the same sequence, still valid when we plug in $-k$ for $k$. Then
\begin{eqnarray*}
\widetilde{\theta}(H_{i})&=&\sum_{finite} a_{ij}\widetilde{\theta}(\Lambda_{j})\\
&=&\sum_{finite} a_{ij}(\binom{-k}{j})_{k\geq 0}\\
&=&\sum_{finite} a_{ij}(Q_{j}(-k))_{k\geq 0}\\
&=&(P_{i}(-k))_{k\geq 0}.
\end{eqnarray*}
\\3. The result follows immediately from $2.$ above together with Theorem~\ref{thm 535}.
\endproof
As a particular consequence of the above proposition, we obtain the following corollary.
\begin{cor} Let $F$ be a field of characteristic $0$ and $\mathcal{H}=(\Gamma^{i})_{i\geqslant 0}$. Let $A$ be a square matrix over $F$ whose characteristic polynomial splits over $F$. Then the sequence matrix obtained by plugging $-k$ for $k$ in the $\mathcal{P}$-cf of $A$ relative to $(\mathcal{S}^{\ast}, \mathcal{H})$ is $\pmb{A}_{d}-\pi_{0}\pmb{0}_{0}$.
\end{cor}
 \proof It is well known that
 \begin{equation*}
(\Gamma^{i})_{i\geqslant 0}=T(\Lambda_{i})_{i\geqslant 0}
\end{equation*}
where $T$ is the infinite invertible lower triangular matrix $(m!S(n,m))_{n,m\geqslant 0}$ and $S(n,m)$ is the Stirling number of the second kind (see, e.g. Riordan~\cite{Riord}).
\\From this result, we deduce on the one hand that $\mathcal{H}$ is contained in the $F$-vector space spanned by $\mathcal{T}$ and on the other hand that $\mathcal{H}$ is, as is well known, a basis of the $F_{\mathcal{S}^{\ast}}$-module $F_{\mathcal{S}^{\ast}}\langle \mathcal{T} \rangle$. The corollary is then a consequence of Proposition~\ref{Prop : 010}.
\endproof
Now let us consider the case where $F=\mathbb{C}$ the complex field. Consider the following sets
\begin{itemize}
\item $\mathcal{S}^{\ast}=\{\pmb{\lambda}=(\lambda^{k})_{k\geqslant 0}/\lambda\in \mathbb{C}, \lambda\neq 0\}$
\item $\widetilde{S}=\{\pmb{\lambda}/\lambda\in \mathbb{R}, \lambda\neq 0\}$
\item $\mathcal{S}^{+}=\{\pmb{\lambda}\in \mathcal{S}^{\ast}/ Im(\lambda)> 0\}$
\item $\mathcal{S}^{-}=\{\pmb{\lambda}\in \mathcal{S}^{\ast}/ Im(\lambda)< 0\}=\{\pmb{\overline{\lambda}}/ \pmb{\lambda}\in \mathcal{S}^{+}\}$
\item $\mathcal{S}^{+}_{1}=\{\frac{\pmb{\lambda}+\pmb{\overline{\lambda}}}{2}/\pmb{\lambda}\in \mathcal{S}^{+}\}=\{[r,\cos(\theta)]/0\neq r\in \mathbb{R}^{+}, \theta\in ]0,\pi[\}$, where $[r,\cos(\theta)]=(r^{k}\cos(k\theta))_{k\geq 0}$
\item $\mathcal{S}^{+}_{2}=\{\frac{\pmb{\lambda}-\pmb{\overline{\lambda}}}{2\mathrm{i}}/\pmb{\lambda}\in \mathcal{S}^{+}\}=\{[r,\sin(\theta)]/0\neq r\in \mathbb{R}^{+}, \theta\in ]0,\pi[\}$, where $[r,\sin(\theta)]=(r^{k}\sin(k\theta))_{k\geq 0}$
    \end{itemize}
Clearly $\widetilde{S}, \mathcal{S}^{+}, \mathcal{S}^{-}$ constitute a partition of $\mathcal{S}^{\ast}$, and then the set $\mathbb{S}=\widetilde{S}\bigcup \mathcal{S}^{+}_{1}\bigcup \mathcal{S}^{+}_{2}$ is $\mathbb{C}$-linearly independent and then is $\mathbb{R}$-linearly independent.
\\From the the general theory of linear recurrence sequences we have the following:
\begin{itemize}
\item $\mathbb{R}_{\mathcal{S}^{\circ}}\bigoplus \mathbb{R}_{\mathbb{S}}$ is the $\mathbb{R}$-vector space of real linear recurrence sequences whose carateristic polynomials are of the form $X^{m}P(X)$ where $P(X)\in \mathbb{R}[X]$ is square-free with nonzero constant terms.
\item $\mathbb{R}_{\mathcal{S}^{\circ}}\bigoplus \mathbb{R}_{\mathbb{S}}[\Gamma]$ is the $\mathbb{R}$-vector space of real linear recurrence sequences whose carateristic polynomials $P(X)\in \mathbb{R}[X]$.
\item If $u\in \mathbb{R}_{\mathcal{S}^{\circ}}\bigoplus \mathbb{R}_{\mathbb{S}}[\Gamma]$ then there exist $\pmb{\rho}_{1},\ldots,\pmb{\rho}_{l}\in \widetilde{S}$, $\pmb{\lambda}_{1}=(r_{1}^{k}e^{\mathrm{i}\theta_{1}}),\ldots,\pmb{\lambda}_{m}=(r_{m}^{k}e^{\mathrm{i}\theta_{m}})\in \mathcal{S}^{+}$, $\mu_{1},\ldots,\mu_{1}\in \mathbb{R}$, $P_{1},\ldots P_{l}\in \mathbb{R}[X]$ and $Q_{1},\ldots Q_{m}\in \mathbb{C}[X]$ such that, for all $k\geq 0$,
    \begin{eqnarray*}
    u_{k}&=&\sum_{i=1}^{q}\mu_{i}\pmb{0}_{i}+\sum_{i=0}^{l}P_{i}(k)\rho_{i}^{k}+
    \sum_{j=0}^{m}(Q_{j}(k)\lambda_{j}^{k}+\overline{Q}_{j}(k)\overline{\lambda}_{j}^{k})\\
    &=&\sum_{i=1}^{q}\mu_{i}\pmb{0}_{i}+\sum_{i=0}^{l}P_{i}(k)\rho_{i}^{k}+
    \sum_{i=0}^{m}(Q_{i}(k)\lambda_{i}^{k}+\overline{Q_{i}(k)\lambda_{i}^{k}})\\
    &=&\sum_{i=1}^{q}\mu_{i}\pmb{0}_{i}+\sum_{i=0}^{l}P_{i}(k)\rho_{i}^{k}+
    \sum_{i=0}^{m}2\Re(Q_{i}(k))[r_{i},\cos(\theta_{i})]_{k}\\
    &&-\sum_{i=0}^{m}2\Im(Q_{i}(k))[r_{i},\sin(\theta_{i})]_{k},
    \end{eqnarray*}
this means that $\mathcal{S}^{\circ}\bigcup \{\pmb{\lambda}\Gamma^{i}/0\neq \lambda\in \mathbb{R}, i\in \mathbb{N}\}\bigcup \{[r,\cos(\theta)]\Gamma^{i}, [r,\sin(\theta)]\Gamma^{i}/ i\in \mathbb{N},\,\,0\neq r\in \mathbb{R}^{+},\,\, \theta\in ]0,\pi[\}$ spans the $\mathbb{R}$-vector space $\mathbb{R}_{\mathcal{S}^{\circ}}\bigoplus \mathbb{R}_{\mathbb{S}}[\Gamma]$, and hence is a basis for it.
\item $\Gamma$ is transcendental over $\mathbb{C}_{\mathcal{S}^{\ast}}$ and it is so over $\mathbb{R}_{\mathbb{S}}$
\end{itemize}
\begin{prop}  Let $A\in M_{q}(\mathbb{R})$ be a real square matrix. Let
$$\mathbb{S}=\{\pmb{\lambda}\Gamma^{i}/0\neq \lambda\in \mathbb{R}, i\in \mathbb{N}\}\bigcup \{[r,\cos(\theta)]\Gamma^{i}, [r,\sin(\theta)]\Gamma^{i}/ i\in \mathbb{N},\,\,0\neq r\in \mathbb{R}^{+},\,\, \theta\in ]0,\pi[\}.$$
Let
$$\pmb{A}= N(A) + \mathcal{B}_{0}\Gamma^{0} + \cdots + \mathcal{B}_{n}\Gamma^{n}$$ be the representation of $A$ with respect to
Then the sequence matrix obtained by plugging $-k$ for $k$ in the $\mathcal{P}$-cf of $A$ relative to $(\mathbb{S}, \mathcal{H})$ is $\pmb{A}_{d}-\pi_{0}\pmb{0}_{0}$.
\end{prop}
\proof The proof follows simply from the fact that the equalities $$\pmb{\lambda}+\pmb{\overline{\lambda}}=2[r,\cos(\theta)]$$ and $$\pmb{\lambda}-\pmb{\overline{\lambda}}=2\mathrm{i}[r,\sin(\theta)]$$ still valid when we plug in $-k$ for $k$.
\endproof
\begin{prop}  Let $A\in M_{q}(\mathbb{R})$ be a real square matrix. Let
$$\mathbb{S}=\{\pmb{\lambda}\Gamma^{i}/0\neq \lambda\in \mathbb{R}, i\in \mathbb{N}\}\bigcup \{[r,\cos(\theta)]\Gamma^{i}, [r,\sin(\theta)]\Gamma^{i}/ i\in \mathbb{N},\,\,0\neq r\in \mathbb{R}^{+},\,\, \theta\in ]0,\pi[\}.$$
Let
$$\pmb{A}= N(A) + \mathcal{B}_{0}\Lambda_{0} + \cdots + \mathcal{B}_{n}\Lambda_{n}$$ be the representation of $A$ with respect to
Then the sequence matrix obtained by plugging $-k$ for $k$ in the $\mathcal{P}$-cf of $A$ relative to $(\mathbb{S}, \mathcal{T})$ is $\pmb{A}_{d}-\pi_{0}\pmb{0}_{0}$.
\end{prop}
\proof The proof follows immediately from the fact that $\mathcal{T}$ is contained in the $\mathbb{R}$-vector space spanned by $\mathcal{H}=(\Gamma^{i})_{i\geq 0}$, since $(\Lambda_{i})_{i\geq 0}=D(\Gamma^{i})_{i\geq 0}$ where
$$D=(\frac{s(n,k)}{n!})_{n,k\geqslant 0}$$ is the infinite lower triangular matrices with coefficients in $\mathbb{R}$ and $s(n,k)$ is the Stirling number of the first kind (see, e.g. Riordan~\cite{Riord}).
\endproof
For the purpose of illustration, let us consider the following examples.
\begin{example} Let
$$B=\begin{pmatrix} 1&1&0&0\\
-2&0&1&0\\2&0&0&1\\-2&-1&-1&-1
\end{pmatrix}.$$
We have $B(k)=$
$$\begin{pmatrix}
\cos(\frac{k\pi}{2})+\sin(\frac{k\pi}{2})&\frac{2\sin(\frac{k\pi}{2})-k\cos(\frac{k\pi}{2})}{2}&
\frac{(1-k)\sin(\frac{k\pi}{2})-k\cos(\frac{k\pi}{2})}{2}&\frac{(1-k)\sin(\frac{k\pi}{2})}{2}\\
-2\sin(\frac{k\pi}{2})&\frac{(k+2)\cos(\frac{k\pi}{2})+(k-1)\sin(\frac{k\pi}{2})}{2}&k\sin(\frac{k\pi}{2})&
\frac{-k\cos(\frac{k\pi}{2})+(k-1)\sin(\frac{k\pi}{2})}{2}\\
2\sin(\frac{k\pi}{2})&\frac{-k\cos(\frac{k\pi}{2})+(1-k)\sin(\frac{k\pi}{2})}{2}&(1-k)\sin(\frac{k\pi}{2})+\cos(\frac{k\pi}{2})&
\frac{k\cos(\frac{k\pi}{2})+(3-k)\sin(\frac{k\pi}{2})}{2}\\-2\sin(\frac{k\pi}{2})&
\frac{k\cos(\frac{k\pi}{2})+(k-3)\sin(\frac{k\pi}{2})}{2}&(k-2)\sin(\frac{k\pi}{2})&
\frac{(2-k)\cos(\frac{k\pi}{2})+(k-3)\sin(\frac{k\pi}{2})}{2}
\end{pmatrix}$$
Since $B(0)=I_{4}$, $B$ is nonsingular and
$$B^{-1}=B(-1)=\begin{pmatrix} -1&-1&-1&-1\\2&1&1&1\\-2&-1&-2&-2\\2&2&3&2\end{pmatrix}.$$
Also we have $B^{-k}=B(-k)$.
\end{example}

\begin{example} Let us take example~\ref{example 1}. We have
$$A_{d}=A(-1)=\begin{pmatrix}
\frac{1}{4}&\frac{1}{4}&\frac{3}{16}&\frac{-1}{16}\vspace*{0.1pc}\\
\frac{1}{4}&\frac{1}{4}&\frac{5}{16}&\frac{-3}{16}\vspace*{0.1pc}\\
0&0&\frac{-1}{4}&\frac{1}{4}\vspace*{0.1pc}\\
0&0&\frac{1}{4}&\frac{-1}{4}
\end{pmatrix}.$$
For all $k\geq 1$,
$$A_{d}^{k}=A(-k)=\begin{pmatrix}
2^{-1-k}&2^{-1-k}&\frac{1}{16}2^{-k}((-1)^{1+k}+5)&\frac{1}{16}2^{-k}((-1)^{k}-1)\vspace*{0.1pc}\\
2^{-1-k}&2^{-1-k}&\frac{5}{16}2^{-k}((-1)^{1+k}+1)&\frac{1}{16}2^{-k}(5(-1)^{k}-1)\vspace*{0.1pc}\\
0&0&(-1)^{k}2^{-1-k}&(-1)^{1+k}2^{-1-k}\vspace*{0.1pc}\\
0&0&(-1)^{1+k}2^{-1-k}&(-1)^{k}2^{-1-k}
\end{pmatrix}.$$
\end{example}
\begin{example} Let $x\in \mathbb{C}$ and let
$$E=\begin{pmatrix}
2\sqrt{3}-x-10&2\sqrt{3}-2x-23&\sqrt{3}-x-5\\4&\sqrt{3}+9&2\\
-2\sqrt{3}+2x+2&-4\sqrt{3}+4x+5&-\sqrt{3}+2x+1
\end{pmatrix}$$
Let
\begin{eqnarray*}
\delta_{s}(x)=\begin{cases}
0 &\text{if}\quad x=0\\x^{s} &\text{if}\quad x\neq 0
\end{cases}
\end{eqnarray*}
and put
$$E(k)=
\begin{pmatrix}
e_{11}(k)&e_{12}(k)&e_{13}(k)\\e_{21}(k)&e_{22}(k)&e_{23}(k)\\e_{31}(k)&e_{32}(k)&e_{33}(k)
\end{pmatrix}$$
where
\begin{eqnarray*}
e_{11}(k)&=&2^{k+1}(\cos(\frac{k\pi}{6})-5\sin(\frac{k\pi}{6}))-\delta_{k}(x)\\
e_{12}(k)&=&2^{k+1}(\cos(\frac{k\pi}{6})-\frac{23}{2}\sin(\frac{k\pi}{6}))-2\delta_{k}(x)\\
e_{13}(k)&=&2^{k}(\cos(\frac{k\pi}{6})-5\sin(\frac{k\pi}{6}))-\delta_{k}(x)\\
e_{21}(k)&=&2^{k+2}\sin(\frac{k\pi}{6})\\
e_{22}(k)&=&2^{k}(\cos(\frac{k\pi}{6})+9\sin(\frac{k\pi}{6}))\\
e_{23}(k)&=&2^{k+1}\sin(\frac{k\pi}{6})\\
e_{31}(k)&=&-2^{k+1}(\cos(\frac{k\pi}{6})-\sin(\frac{k\pi}{6}))+2\delta_{k}(x)\\
e_{32}(k)&=&-2^{k+2}(\cos(\frac{k\pi}{6})-\frac{5}{4}\sin(\frac{k\pi}{6}))+4\delta_{k}(x)\\
e_{33}(k)&=&-2^{k}(\cos(\frac{k\pi}{6})-\sin(\frac{k\pi}{6}))+2\delta_{k}(x)
\end{eqnarray*}
We have, for all $k\geq1$,
$E^{k}=E(k)$ and
$$E(0)=\begin{pmatrix} 2-\delta_{0}(x)&2-2\delta_{0}(x)&1-\delta_{0}(x)\\0&1&0\\-2+2\delta_{0}(x)&-4+4\delta_{0}(x)&-1+2\delta_{0}(x)\end{pmatrix}$$
Then $E$ is nonsingular if and only if $x\neq 0$.
$$E_{d}=\begin{pmatrix} \frac{\sqrt{3}+5}{2}-\delta_{-1}(x)&\frac{2\sqrt{3}+23}{4}-2\delta_{-1}(x)&\frac{\sqrt{3}+5}{4}-\delta_{-1}(x)\vspace*{0.1pc}\\
-1&\frac{\sqrt{3}-9}{4}&\frac{-1}{2}\vspace*{0.1pc}\\\frac{-\sqrt{3}-1}{2}+2\delta_{-1}(x)&\frac{-4\sqrt{3}-5}{4}+4\delta_{-1}(x)&
\frac{-\sqrt{3}-1}{4}+2\delta_{-1}(x)\end{pmatrix}$$
and for all $k\geq1$
$$E_{d}^{k}=\begin{pmatrix}
a_{11}(k)&a_{12}(k)&a_{13}(k)\\a_{21}(k)&a_{22}(k)&a_{23}(k)\\a_{31}(k)&a_{32}(k)&a_{33}(k)
\end{pmatrix}$$
where
\begin{eqnarray*}
a_{11}(k)&=&2^{-k+1}(\cos(\frac{k\pi}{6})+5\sin(\frac{k\pi}{6}))-\delta_{-k}(x)\\
a_{12}(k)&=&2^{-k+1}(\cos(\frac{k\pi}{6})+\frac{23}{2}\sin(\frac{k\pi}{6}))-2\delta_{-k}(x)\\
a_{13}(k)&=&2^{-k}(\cos(\frac{k\pi}{6})+5\sin(\frac{k\pi}{6}))-\delta_{-k}(x)\\
a_{21}(k)&=&-2^{-k+2}\sin(\frac{k\pi}{6})\\
a_{22}(k)&=&2^{-k}\cos(\frac{k\pi}{6})-9\times2^{-k}\sin(\frac{k\pi}{6})\\
a_{23}(k)&=&-2^{-k+1}\sin(\frac{k\pi}{6})\\
a_{31}(k)&=&-2^{-k+1}(\cos(\frac{k\pi}{6})+\sin(\frac{k\pi}{6}))+2\delta_{-k}(x)\\
a_{32}(k)&=&-2^{-k+2}(\cos(\frac{k\pi}{6})-\frac{5}{4}\sin(\frac{k\pi}{6}))+4\delta_{-k}(x)\\
a_{33}(k)&=&-2^{-k}(\cos(\frac{k\pi}{6})+\sin(\frac{k\pi}{6}))+2\delta_{-k}(x)
\end{eqnarray*}
\end{example}
\begin{example} Let $p\in \mathbb{N}, p\geqslant 2$ and consider the following circulant matrices over $\mathbb{C}$
$$A=\begin{pmatrix}
1&\cdots&1\\
\vdots&&\vdots\\
1&\cdots&1
\end{pmatrix},
\quad B=\frac{1}{p-1}\begin{pmatrix}
0&1&\cdots&1\\
\vdots&&&\vdots\\
1&\cdots&1&0
\end{pmatrix}
\quad C=\frac{1}{p}\begin{pmatrix}
p-1&1&\cdots&1\\
\vdots&&&\vdots\\
1&\cdots&1&p-1
\end{pmatrix}
$$
where $p\in \mathbb{N}, p\geqslant 2$.
\\It is clear that $A^{k}=p^{k-1}A$ for all $k\geqslant 1$. Since $B=\frac{1}{p-1}(A-I_{p})$, it follows that $B^{k}=a_{k}B+b_{k}I_{p}, k\geqslant 1$, where $$a_{k}=\frac{p-1}{p}(1)^{k}-\frac{p-1}{p}\left(\frac{-1}{p-1}\right)^{k} \quad\text{and}\quad b_{k}=\frac{1}{p}(1)^{k}+\frac{p-1}{p}\left(\frac{-1}{p-1}\right)^{k},\quad k\geqslant 1,$$
From this last result we deduce the following:
\begin{itemize}
\item From Lemma~\ref{lem 33} it follows that The geometric part of $\pmb{B}$ is $\pmb{a}B+\pmb{b}I_{p}$, where $a_{0}=0$ and $b_{0}=1$ are obtained by plugging $0$ for $k$ in $a_{k}$ and $b_{k}$, and that The non-geometric part of $\pmb{B}$ is $(B^{0}-(a_{0}B+b_{0}I_{p}))\pmb{0}_{0}=\pmb{0}$.
\item The eigenvalues of $B$ are $1$ and $\displaystyle\frac{-1}{p-1}$ and the nonzero eigenvalue of $A$ is $p$.
\item The geometric part of $\pmb{A}$ is $\displaystyle\frac{1}{p}\pmb{p}A$ and the non-geometric part of $\pmb{A}$ is $\displaystyle(A^{0}-\frac{1}{p}A)\pmb{0}_{0}=C\pmb{0}_{0}$.
\item The spectral projections of $A$ and $B$ are $\pi(A)_{0}=C, \pi(A)_{p}=\displaystyle\frac{1}{p}A$ and $\pi(B)_{1}=\displaystyle\frac{p-1}{p}B+\frac{1}{p}I_{p}, \pi(B)_{\frac{1}{1-p}}=\displaystyle\frac{p-1}{p}(I_{p}-B)$.
\item From Corollary~\ref{Cor 22} it follows that the minimal polynomials of $A$ and $B$ are $m_{A}(X)=X(X-p)$ and $m_{B}(X)=\displaystyle(X-1)(X+\frac{1}{p-1})$.
    \item $B^{k}=\pi(B)_{1}+(1-p)^{-k}\pi(B)_{\frac{1}{1-p}}$, for all $k\in \mathbb{Z}$.
    \item $A_{d}^{k}=p^{-k-1}A$ for all $k\geqslant 1$.
\end{itemize}
\end{example}
\begin{thebibliography}{99}
\bibitem{Ben} A. Ben-Israel and T.N.E. Greville. \emph{Generalized inverse Theory and Applications.} 2nd Edition, New York, Springer Verlag, (2003).

\bibitem{Cohn} P.M. Cohn. R. \emph{Basic Algebra.} Springer, London, (2003).

\bibitem{Draz}  M.R. Drazin, \emph{Pseudo-inverses in associative rings and semigroups.}
Amer. Math. Monthly. {\bf 65}(1958), 506-514.

\bibitem{Fill} J.P. Fillmore and M.L. Marx, \emph{Linear recursive sequences.} SIAM Rev. {\bf 10}(1968), 342-353.

\bibitem{Riord} J. Riordan. \emph{Combinatorial Identities.} John Wiley $\&$ Sons, Inc, New York, (1968).

\bibitem{Male} B. Malesevic and I. Jovovic. \emph{A procedure for finding the k-th power of a matrix.} Maplesoft, (2007) (accessed July 05, 2020).
\bibitem{Mou1} M. Mou\c{c}ouf, \emph{Arbitrary positive power of semicirculant and $r$-circulant matrices,} 	arXiv:2006.15048 [math.RA].
\bibitem{Mou2} M. Mou\c{c}ouf, \emph{A closed-form expression for the kth power of semicirculant and $r$-circulant matrices,} 	 arXiv:2006.16198 [math.RA].
\end{thebibliography}
\end{document} 